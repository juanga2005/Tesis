%%%%%%%%%%%%%%%%%%%%Tesis File%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{book}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[pdftex]{graphicx}
\usepackage{setspace}
\usepackage{mathrsfs}
\usepackage{float}
%\usepackage{pbox}





\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
 %\usepackage{fancyhdr,floatpag}

%\pagestyle{fancy}
%\fancyhf{}% Clear page header/footer
%\renewcommand{\headrulewidth}{0pt}% No header rule
\fancyfoot[C]{\thepage}

%\floatpagestyle{fancy}% Page style for float-page only
%Theorems
\newtheorem{definition}{Definition}




%Commands

%Prior, posterior and likelihood
\newcommand{\post}{\mathbb{P}_{post}}
\newcommand{\like}{\mathbb{P}_{like}}
\newcommand{\prior}{\mathbb{P}_{prior}}
\newcommand{\p}{\mathbb{P}}


%Other commands
\newcommand{\E}{\mathbb{E}} %Expectation
\newcommand{\tvs}{\mathscr{T}} %TVS symbol
\newcommand{\x}{\textbf{x}}
\newcommand{\y}{\textbf{y}}
\newcommand{\vv}{\textbf{v}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\dv}{\nabla\cdot}



\begin{document}
\setlength{\unitlength}{1 cm} %Especificar unidad de trabajo
\thispagestyle{empty}
\begin{center}
    %\begin{picture}(18,4)
    %\centering
    \includegraphics[scale=0.5]{log.png} \\[1cm]
    %\end{picture}
\textbf{{\LARGE Simon Fraser University}\\[0.5cm]
{\LARGE Faculty of Sciences, Math Department}}\\[1.25cm]
\begin{doublespace}
{\huge \textbf{Here comes the title}}\\[1.5cm]
\end{doublespace}
{\large Juan Gabriel Garc{\'i}a Osorio}\\[1cm]
Advisor: John Stockie\\[1cm]
Commitee: Paul Tupper\\[1cm]
Burnaby B.C - May  2017
\end{center}

\newpage
\tableofcontents


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Acknowlegments}
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 1: Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 2: Theoretical and Computational Framework %%%%%%%%%%%%%%%%
\chapter{Theoretical and Computational Framework}
%\pdfmarkupcomment[markup=Squiggly,color=green]{what eve}{Change this shit}


The framework of Bayesian statistics is the foundation of  our approach to estimate parameters and solve 
inverse problems. Unlike frequentist statistics, in the Bayesian approach, randomness
is a measure of uncertainty,  not a matter of frequency. Consider an statement such  as:
the probability of having life in the universe is 0.01. In the frequentist
perspective, this number is interpreted as: for every hundred planets, on average, one planet shelters life.
 In the Bayesian
perspective the number 0.01 is interpreted as a measure of how certain we are about life in the universe
given the current state of knowledge about the outer space. 
Clearly there is a big philosophical
difference between these two approaches that has a direct impact in how far reaching is each point of view  \cite{jaynes2003probability}.


%Talking about Bayes rule
At this point we mention that when we talk about uncertainty we are talking about every possible 
source of randomness  or  lack of information. That is, the use of the word uncertainty in this work
is related to either epistemic (A phenomenon might not be random but the complete lack of 
understanding of it makes us see it as random) or aleatory (Inherent to the nature of phenomenon, for 
example this is the kind of randomness physicists believe is happening in quantum mechanics)
\cite{kennedy2001bayesian}. In real life the uncertainty associated with a  measurement or  quantity 
of interest is usually connected  with the uncertainty  of other variables involved in the problem under study. 
The Bayesian framework provides a rigorous framework to study these uncertainties, 
using whatever information is available for the problem. The cornerstone of this framework
in the mathematical language is known as   Bayes' formula given by

\begin{equation}\label{eqnBayes}
\post(A|B)=\frac{1}{Z}\like(B|A)\prior(A).
\end{equation}
Intuitively, Bayes' rule says that the probability of the event $A$ to happen given that $B$ was observed is
proportional to the probability of $B$ to happen given $A$ was observed. This value is weighted by 
the probability of $A$ to happen. Finally, $Z$ is a normalization constant.

Let us make sense of  equation \ref{eqnBayes} in a more rigorous setting. 
We begin with the following definitions taken from
\cite{dudley2002real}.
\begin{definition}\label{dfnprobabilitytriple}
A probability space is a triple $(\Omega,\mathscr{F},\p)$, where $\Omega$ is a set called 
sample space, $\mathscr{F}$ is a collection of subsets of $\Omega$ that satisfies
\begin{enumerate}
\item $\emptyset,\Omega\in\mathscr{F}$.
\item If $A\in\mathscr{F}$ then $A^{c}\in\mathscr{F}$.
\item If $A_{1},A_{2},\ldots \in\mathscr{F}$ then $\bigcup_{i\in\mathbb{N}}A_{i}\in\mathscr{F}$.
\end{enumerate}
A  collection of sets that satisfies properties 1 to 3 is called a $\sigma-$ algebra and its elements are called
events. 
\\
The map $\p:\mathscr{F}\rightarrow [0,1]$ is called a probability measure and satisfies
\begin{enumerate}
\item $\p(\Omega)=1$.
\item If $A_{1},A_{2},\ldots \in\mathscr{F}$ are pairwise disjoint, then 
\begin{equation*}
\p(\bigcup_{i\in\mathbb{N}}A_{i})=\sum_{i\in\mathbb{N}}\p(A_{i}).
\end{equation*}
\end{enumerate}
\end{definition}

\begin{definition}
Given a probability space $(\Omega,\mathscr{F},\p)$ and two events $A,B\in\mathscr{F}$, with $\p(B)\neq 0$. 
We define the conditional probability of $A$ given $B$ by

\begin{equation*}
\p(A|B)=\frac{\p(A\cap B)}{\p(B)}.
\end{equation*}
\end{definition}



%In equation (\ref{eqnBayes}), $\p,\prior,\like,\post$ are different probability measures defined in the
%same sample space $\Omega$. 
Going back to equation (\ref{eqnBayes}), the sets $A$ and $B$ are subsets of the sample space $\Omega$ and 
are elements of the associated $\sigma-$algebra $\mathscr{F}$. The  notation
 $\like(\cdot|\cdot)$ or $\post(\cdot|\cdot)$, denotes conditional probability. Let us introduce some terminology:
 the term $\like(B|A)$ is called the \textit{likelihood} of $B$ given $A$. The term $\prior(A)$ is called the 
\textit{prior} probability for $A$. The prior probability expresses how much we believe the event $A$ 
to happen without assuming
anything about  $B$. The reciprocal of $Z$ is a \textit{normalization constant} defined as 

\begin{equation}\label{eqnNormalizationConstant}
Z=\int_{\Omega} \like(B|A)d\prior.
\end{equation}

The term $\post(A|B)$ is  the \textit{posterior} probability of $A$ given $B$. The integral
is understood in the  Lebesgue sense as the  integral with respect to the measure $\prior$ \cite{lerner2014course}. 
The posterior contains  the information 
that we gained by comparing our beliefs (decoded in the prior probability) with experimental data 
(decoded in the likelihood). 
\newline



%Ilustratory example
Now we look at the connection between Bayesian statistics and  the field of inverse problems. 
Inverse problems are  often concerned with finding the cause of an effect. Whereas a forward
problem is concerned with finding the effect of a cause. If we have information about the 
forward problem, then we can use it to get information about the inverse problem. Bayes rule
puts in a mathematical language the connection between inverse and forward problem. 
If we consider the cause to be the
event $A$ and the effect the event $B$, then the information of the forward problem
is encoded in $\like(B|A)$. The information of the inverse problem is contained in 
$\post(A|B)$. That is why in the Bayesian framework, the posterior probability
is the $\textit{solution to an inverse problem}$.

Often, inverse problems
are ill-posed, this means
that these problems might  not satisfy one or more of the following properties \cite{lebedev2012functional}:

\begin{itemize}
\item Existence: There exists a solution for the problem.
\item Uniqueness: The problem has a unique solution.
\item Stability: Small changes in inputs result in small changes in outputs.
\end{itemize}
This is a serious issue. For example, if the problem under study has at least one solution
but is unstable to small perturbations, how can we assess the accuracy of the solution to 
the problem. 
Therefore an statistical or non-deterministic approach is called for . As explained before, the Bayesian framework 
is useful in this context. Bayes'rule connects the inverse problem  of finding the cause
of an effect through the posterior with the forward problem of finding the effect of a cause
through the likelihood in a way that is possible to quantify the uncertainty about the solution
of the problem. Let us  clarify with an example of how the Bayesian framework can be used to solve inverse problems. 
\newline

Consider the problem of finding the launch location of a rock that impacted (and cracked) a window. 
We can start by considering the following events
\begin{align*}
& A=\text{Coordinates of the launching location}.\\
& B= \text{Coordinates of the  location impact in the window}.
\end{align*}
Here we assume we know $B$, but $A$ is unknown. We can use Bayes' rule to estimate $A$ through
the posterior $\post(A|B)$. In this case
we need to find the connection with the forward problem, i.e. given 
the launch coordinates find the location impact. This connection is encoded in the likelihood $\like(B|A)$.
In addition we also need to set the prior probability for $A$. 
\newline



Let us explain how we could estimate the different probabilities mentioned in the previous paragraph. 
First, to find the likelihood
we need to know how the rock's impact position  in the window  is related to the launch location. 
If we treat air resistance as a source of uncertainty  we can use
the kinematics equations  for parabolic trajectories to get \cite{arnol2013mathematical}
\begin{equation}\label{eqnKinematics}
\textbf{r}=\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2},
\end{equation} 
where $\textbf{r}$ and $\textbf{r}_{0}$ are the final and initial position of the rock, 
$\textbf{v}_{0}$ is 
the initial velocity of it,  and $\textbf{g}$ is  a vector that points to the center of the earth and has a 
magnitude equal to the value of the acceleration of gravity. The scalar $t$ represents time.
In a more physical language, to compute the likelihood it is necessary to estimate $\textbf{r}$ (where the 
rock hit the window) assuming we know $\textbf{r}_{0}$ (where it was thrown), and the initial velocity 
of the rock $\textbf{v}_{0}$. 
Once all the other variables are identified the value of $t$ can be computed in a straightforward manner. 

Equations in physics are just models of reality and as such are just an approximation to it. To take
this into account we add an extra layer to the model by adding a random parameter that accounts
for the discrepancy of our model with reality. We propose 
\begin{equation}\label{eqnParabolicEpsilon}
\textbf{r}=\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2}+\mathbf{\epsilon},
\end{equation} 
where $\mathbf{\epsilon}$ is a \textit{random vector} distributed as \textit{multivariate Gaussian}. 
Before we proceed it is necessary to define more terminology and mathematical objects  that are going 
to be used throughout the rest of the text. 

\begin{definition}
Given a set $\Omega$, for any subset $T\subset\Omega$, we define the $\sigma-$algebra generated by $T$ as
the smallest $\sigma-$algebra in $\Omega$ that contains $T$.
\end{definition}

\begin{definition}
Let $O$ be the set of all open sets in $\mathbb{R}^{n}$. The $\sigma-$algebra generated by $O$ is called
the Borel $\sigma-$algebra and is denoted by $\mathcal{B}^{n}$. If $n=1$ we set 
$\mathcal{B}^{1}:=\mathcal{B}$.
\end{definition}

\begin{definition}
Given a probability space $(\Omega,\mathscr{F},\p)$, a function $X:\Omega\rightarrow\mathbb{R}$ is called 
a random variable
if $X^{-1}(C)\in\mathscr{F}$ for all $C\in\mathcal{B}$.
\end{definition}

\begin{definition}
 An $n$-dimensional random vector $\textbf{X}=(X_{1},\ldots,X_{n})$ in $(\Omega,\mathscr{F},\p)$ 
is a function $\textbf{X}:\Omega\rightarrow\mathbb{R}^{n}$, such that each component is a random variable. 
Note that a random variable can be considered as a one dimensional random vector.
\end{definition}

\begin{definition}
Given a probability space $(\Omega,\mathscr{F},\p)$ and an $n$-dimensional  random vector 
$\mathbf{X}:\Omega\rightarrow\mathbb{R}^{n}$.
Its distribution  is the probability measure
\begin{equation*}
\mu:\mathcal{B}^{n}\rightarrow [0,1],
\end{equation*}
where  $\mu$ defined by 
\begin{equation*}
\mu:=\p\circ \textbf{X}^{-1}.
\end{equation*}
\end{definition}
\begin{definition}
Given a random vector $\textbf{X}:\Omega\rightarrow\mathbb{R}^{n}$ with
probability distribution $\mu$. We say that $\mathbf{X}$ is absolutely 
continuous with respect to the Lebesgue measure if there exists a real valued, integrable function $\rho$
such that for all $C\in\mathcal{B}^{n}$ we have
\begin{equation*}
\mu(C)=\int_{C}\rho(x)dx.
\end{equation*}
We say that $\rho$ is the density function for $\mathbf{X}$.
\end{definition}
\begin{definition}\label{dfnrandonvariables}
Given an $n$ dimensional random vector $\mathbf{X}$ such that for any 
$C\in\mathcal{B}^{n}$ we have
\begin{equation}\label{eqnmultivariateGaussianDefinition}
\mu(C)=\int_{C}
\frac{1}{2\pi det(\Sigma)^{-\frac{1}{2}}}\exp((\textbf{x}-\textbf{x}^{*})^{T}\Sigma^{-1}
(\textbf{x}-\textbf{x}^{*}))d\textbf{x},
\end{equation}
then we say
that $\textbf{X}$ has multivariate Gaussian distribution or just Gaussian, 
with mean $\textbf{x}^{*}\in\mathbb{R}^{n}$
and covariance matrix $\Sigma$. The matrix $\Sigma$ is symmetric and positive definite. We shall write
\begin{equation}\label{eqnMultivariate}
\textbf{X}\sim \mathcal{N}(\textbf{x}^{*},\Sigma).
\end{equation}
In this case the components of $\textbf{X}$ are said to be \textit{jointly Gaussian}.
\end{definition}

We now return to equation (\ref{eqnParabolicEpsilon}). We assume $\epsilon\sim\mathcal{N}(0,\sigma^{2}I)$.
Here $I$
represents the $3\times 3$ identity matrix and $\sigma>0$ parametrizes One belief in quantifying the 
accuracy  
of equation (\ref{eqnKinematics}).  By introducing a random variable into the model
we make all variables involved  in equation (\ref{eqnKinematics})
to be  random variables, that is, we now look at the  associated stochastic equation. With this notation
we can cast equation (\ref{eqnBayes}) into  (assuming independence between $\textbf{r}_{0}$ and $\textbf{v}_{0}$)
\begin{equation}\label{eqnpostrock}
\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})=\frac{\like(\textbf{r}|\textbf{r}_{0},\textbf{v}_{0})
\prior(\textbf{r}_{0})}{Z}.
\end{equation}



Since $\mathbf{\epsilon}$ is Gaussian we can readily obtain \cite{Somersalo}
\begin{equation*}
\textbf{r}|\textbf{r}_{0},\textbf{v}_{0}\sim \mathscr{N}(\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2}
,\sigma^{2} I).
\end{equation*}
This last equation gives an explicit density for the likelihood. 

We now turn our attention to  the prior.
Suppose that we suspect that the rock was thrown from the bedroom of one of our neighbors.
 One way to model this suspicion is to assume a prior distribution on $\textbf{r}_{0}$ as
\begin{equation*}
\textbf{r}_{0}\sim\mathscr{N}(\textbf{w},\lambda^{2} I),
\end{equation*}
where $\textbf{w}$ is the coordinate vector of the center of mass of our neighbor's room and $\lambda$ represents 
One belief the launch location is at the point $\textbf{w}$. We note that  this is one way to model 
 prior knowledge and other priors are also possible for our problem. Finally the normalization constant $Z$
is given by the expression in equation (\ref{eqnNormalizationConstant}). Explictly we have
%probabilities  are normalized, if we integrate over the whole space equation (\ref{eqnpostrock}), we get
%\begin{eqnarray*}
%1=\int_{\mathbb{R}^{3}}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})d\textbf{r}_{0}\\
%=\int_{\mathbb{R}^{3}}\frac{\like(\textbf{r}|\textbf{r}_{0},\textbf{v}_{0})
%\prior(\textbf{r}_{0})}{\p(\textbf{r}|\textbf{v}_{0})}d\textbf{r}_{0}.
%\end{eqnarray*} 
%Since the denominator in the last integrand is  constant with respect to the variable of integration 
%we conclude
\begin{align*}
Z&=\int_{\mathbb{R}^{3}}\like(\textbf{r}|\textbf{r}_{0},\textbf{v}_{0})
\prior(\textbf{r}_{0})d\textbf{r}_{0}\\
&= \frac{1}{(2\pi)^{6}(\sigma\lambda)^{3}}\int_{\mathbb{R}^{3}}
\exp(-\frac{1}{2\sigma^{2}\lambda^{2}}
\left(\|\textbf{r}-(\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2})\|^{2}
+\|\textbf{r}_{0}-\textbf{w}\|^{2}\right)d\textbf{r}_{0}.
\end{align*}


Having the likelihood, prior and normalization constant allow us to compute the posterior using
Bayes rule. With these probabilities calculated 
we can obtain different kind of estimates for the value $\textbf{r}_{0}$.  
Common choices of pointwise estimates include

%
%
%For the moment assume we have the means to sample from the 
%posterior in equation (\ref{eqnpostrock}). By having samples from the posterior we can obtain
%pointwise estimates of the parameters of interest. Common choices of pointwise estimates
%include
\begin{eqnarray}\label{eqnpointestimates}
\textbf{r}_{MAP}=argmax_{\textbf{r}_{0}}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0}) 
\qquad\text{(Maximum a posteriori),}\\
\textbf{r}_{CM}=\int_{\mathbb{R}^{3}}\textbf{r}_{0}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})d\textbf{r}_{0}.
\qquad\text{(Conditional mean)}, \\
\textbf{r}_{ML}=argmax_{\textbf{r}_{0}}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0}).
\qquad\text{(Maximum likelihood).}
\end{eqnarray}

Each  of these estimates have strengths and weaknesses. If the posterior is bimodal, then the conditional
mean might point at a value with very low probability, whereas the maximum a posteriori might be more 
reliable. If the posterior has no critical points then the mean might be use as a point estimate. We can 
also assess how confident we are about the point estimate. For example, if $\textbf{r}^{*}$ is our point
estimate we can calculate a number $\alpha>0$ such that

\begin{equation*}
\int_{B(\textbf{r}^{*},\alpha)}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})d\textbf{r}_{0}=0.95,
\end{equation*}

where $B(\textbf{r}^{*},\alpha)$ is the ball centered at $\textbf{r}^{*}$ and radius $\alpha$. This 
value of $\alpha$ can be thought of as  the Bayesian version 
of the frequentist's $95\%$ confidence interval.
Another way to estimate the uncertainty is by calculating the covariance matrix of $\textbf{r}$
around $\textbf{r}_{0}$ as
\begin{equation*}
\int_{\mathbb{R}^{3}}(\textbf{r}_{0}-\textbf{r}^{*})\otimes(\textbf{r}_{0}-\textbf{r}^{*})d\post.
\end{equation*}
\newline
The diagonal of this matrix will  contain the variance of each of the coordinates of $\textbf{r}^{*}$.

Note that the posterior is a probability density and it does not necessarily have a closed form. This
makes difficult to calculate the uncertainties we mentioned above.
Hence we need a way of extracting information from the posterior. One approach is to generate 
independent samples
from it and do a Monte Carlo integration   to obtain the different uncertainty estimates. 
How to sample from a probability 
density and do a Monte Carlo integration are going to be explained in Chapter 3. For the moment
assume it is possible to evaluate any of the point estimates and the uncertainty measures. With 
this we obtained a way to estimate the launch location of the rock and how confident we are
about that estimate. 
\newline


%Caveats of computing complex models
Practical problems are often substantially more challenging than in the above example. Often times we have to 
deal with several issues such as 

\begin{enumerate}
\item Uncertainties in experimental measurements.
\item Lack of sufficient information and data.
\item Computational complexity of  physical models that are too expensive to evaluate.
\item Parameters that might belong to high dimensional spaces so the associated probability density is 
hard to sample from.
\item Evaluating any of the possible point estimates for the quantity of interest might be very hard.
\end{enumerate}
In the problem that we outlined in  Chapter 1, we have to deal with all of  the above mentioned issues.
In this chapter we are going to discuss our approach to deal with issues 3, 4 and 5 above. We 
omit 1 and 2, since these  are intrinsic to the physics of the problem and   the methodology used 
to obtain the experimental data, and so, are out of our hands.


%%%%Dealing with computational complexity
\section{Dealing with  the computational complexity of the physical model}
Models of physical processes are often complex and   expensive to simulate numerically, therefore we need
a way of reducing this complexity.
Following O'Hagan  \cite{o2006bayesian}, we think of our  mathematical model of the physical process
 as a function
$M(\cdot)$ so that $y=M(\x)$ where $\x\in\mathbb{R}^{n}$   and $y\in\mathbb{R}$.
Mathematical models are approximations to physical processes and as such there are discrepancies between
models and reality. It is then necessary to address the validity  of the model. One way to do
this is by performing a sensitivity analysis on the parameters the model depend on. Roughly, we choose a
combination of different values of the parameters and then we assess the importance of each one in
the output of the model. This means that we need to run the model $M(\cdot)$ for a large set 
of different combination of its parameters.
Since mathematical models are expensive,
this implies that   the  use of   classical methods such  as correlation
ratios, FAST method, Method of Sobol', etc. 
 are not feasible (see \cite{saltelli2000sensitivity} for details). 

Here the concept of emulator as defined in \cite{o2006bayesian} 
comes into play. We 
approximate the function $M(\cdot)$, which is  expensive to evaluate,
 with a function $\widehat{M}(\cdot)$ that is cheap to evaluate. To construct such an approximation,   
we  associate a 
probability distribution to each  possible value of $M(\textbf{x})$ and for example take 
$\widehat{M}(\x)$ to be  the mean
of this distribution. We will refer to $\widehat{M}(\cdot)$ as an emulator. 
Following \cite{o2006bayesian} we expect the emulator to satisfy the conditions in 
the following definition
\begin{definition}\label{dfnEmulator}
An emulator $\widehat{M}(\cdot)$ of a function $M(\cdot)$, is a map that:
\begin{itemize}
\item At points $\{\x\}_{k=1}^{N}$  were we know the output of the mathematical model i.e. we know 
$M(\x_{k})$ for $k=1,2,\ldots, N$,
the emulator should satisfy $\widehat{M}(\x_{k})=M(\x_{k})$.
\item For  points $\{\x_{k}^{*}\}_{k=1}^{T}$ where we don't know the output $M(\x_{k}^{*})$, the emulator should
give back an estimate $\widehat{M}(\textbf{x}_{k}^{*})$, based on the distribution for $M(\textbf{x}_{k}^{*})$. 
That estimate should reflect the uncertainty associated with
the interpolation/extrapolation done at that point.
\end{itemize} 
\end{definition}


From now on in this work we are going to refer to the mathematical model or the computationally expensive
function to calculate as $M(\cdot)$. The emulator that approximates this function is going to be denoted by 
$\widehat{M}(\cdot)$.
%Talking about Gaussian processes

A very popular  method to construct an emulator with the desired
extrapolation/interpolation properties is what is known as a Gaussian process regression.  

\subsection{Gaussian Processes}
The conditions on the emulator $\widehat{M}(\cdot)$, imply that we need
to work with a probability distribution for each point $\textbf{x}$ in the domain of the model $M(\cdot)$.
This means that  we need to work with 
 a set of random variables  with high cardinality. 
When dealing with 
several random variables there is one probability density that is computationally tractable and
easy to work with: the multivariate Gaussian distribution (see Definition \ref{dfnrandonvariables}). 
The computational tractability  of the multivariate Gaussian distribution, can be used as a justification
to define what a Gaussian process is.
\begin{definition}\label{dfnGP}
A Gaussian process (GP) is a collection of random variables $\{g(x)\}_{x\in A}$, for some set $A$, 
possibly uncountable,
 such that any finite subset of random variables
 $\{g(x_{k})\}_{k=1}^{N}\subset\{g(x)\}_{x\in A}$ for 
$\{x_{k}\}_{k=1}^{N}\subset A$ are jointly Gaussian
\cite{rasmussen2006gaussian}. 
\end{definition}

A GP is specified by a mean function and a covariance operator or covariance kernel. 
Following  Rasmussen \cite{rasmussen2006gaussian} we define
\begin{align*}
& m(x):=\E(g(x)),&&\qquad\text{(Mean)}\\
& k(x,x'):=\E((g(x)-m(x))(g(x')-m(x')))&&\qquad\text{(Kernel)}.
\end{align*}
If $\{g(x)\}_{x\in A}$ is a GP with mean $m(x)$ and covariance $k(x,x')$ we will write
\begin{equation*}
g(x)\sim \textbf{GP}(m(x),k(x,x')).
\end{equation*} 

To  understand why the notion of a GP is useful for us, recall that our goal is to create
an emulator $\widehat{M}(\cdot)$ that approximates a function $M(\cdot)$. 
For a fixed $\x\in A$, a realization of the  random variable $g(\x)$ represents
a possible value of $M(\x)$. The mean function at that point $\x$, i.e. $m(\x)$ 
represents the best prediction about the true value of $M(\x)$. We may set
$\widehat{M}(\x)=m(\x)$. Later we will show that one way to measure the  uncertainty 
associated with that prediction is given by the quantity $k(\x,\x)$.

 

We are going to use GPs to fit  functions in  high dimensional euclidean spaces, so from 
now on we may think
of the  index set $A$ of Definition \ref{dfnGP} as a subset of $\mathbb{R}^{n}$ for some $n\geq 1$. 
\newline

The reason why  Gaussian processes are useful in practice is that  they are 
completely characterized by the mean $m(x)$ and the covariance kernel $k(x,x')$\cite{lifshits2012lectures}. 
 For example a  common covariance or kernel is the
 squared exponential (SE) function given by  
\begin{equation}\label{eqnsquareexponential}
k(x,x')=e^{-\frac{1}{2}\|x-x'\|_{2}^{2}}.
\end{equation}
We choose to use the name squared exponential instead of 
Gaussian to avoid confusion with
the probability distribution.
This  covariance function tells us that if $\x,\x'$ are close in the Euclidean metric 
then they are highly correlated whereas far away points have a correlation that decays exponentially fast.
How to choose the covariance function depends on the kind
of regularity we want for the realizations of the GP. We will discuss this topic in
more detail later in the chapter. For the moment for reference purposes, we show 
some of the most common kernels used in practice \cite{rasmussen2006gaussian} (setting $r=\|x-x'\|_{2}$)

\begin{itemize}
\item Squared-Exponential: $k(r;\theta)=e^{-\frac{1}{2}(\frac{r}{\theta})^{2}}$
\item Exponential: $k(r;\theta)=e^{-\frac{r}{\theta}}$\\
\item Matern $\frac{3}{2}: k(r;\theta)=(1+\frac{\sqrt{3}r}{\theta})e^{-\frac{\sqrt{3}r}{\theta}}$.
\item Matern $\frac{5}{2}: k(r;\theta)=(1+\frac{\sqrt{5}r}{\theta}+\frac{5}{3}
(\frac{r}{\theta})^{2})e^{-\frac{\sqrt{5}r}{\theta}}$.
\item Power-Exponential: $k(r;\theta,p)=e^{-(\frac{r}{\theta})^{p}}$.
\end{itemize}





\subsubsection{Gaussian Processes as Distributions Over Function Spaces}

Alternatively GPs can be viewed as  measures on function spaces. We now discuss them in this
context following the approach of \cite{lifshits2012lectures}.
\newline
Interesting function spaces (e.g. $L^{p}$ spaces, Sobolev spaces, etc...) are 
normed vector spaces, with a topology inherited from the metric induced by the norm, and so 
, interesting function spaces are topological vector spaces (TVS). 

Let $\mathscr{T}$ be a TVS and  let $\mathscr{T}^{*}$ be its topological dual. 
We will denote the action of an 
element $h\in\tvs^{*}$ over an element $z\in\tvs$ with $\langle h,z\rangle$. Moreover 
we  define a random variable taking values in $\tvs$ as a map 
\begin{equation*}
X:(\Omega,\mathscr{F},P)\longrightarrow\tvs,
\end{equation*}
that is measurable with respect to the $\sigma$-algebra generated by the open sets
of $\tvs$. This $\sigma$-algebra is known as the Borel $\sigma$-algebra for $\tvs$.
The triple $(\Omega,\mathscr{F},P)$ is a probability space as in Definition \ref{dfnprobabilitytriple}. 
We use the shorthand notation  $X\in\tvs$ whenever the random variable $X$ takes values in $\tvs$. 
For example if $\tvs=L^{2}(\mathbb{R})$,  then  $X\in L^{2}(\mathbb{R})$ means that $X$ is a measurable
map from the probability space $(\Omega,\mathscr{F},P)$ into $L^{2}(\mathbb{R})$.

We say that a random variable $X\in\tvs$ is called Gaussian if $\langle h,X\rangle$ is
a Gaussian random variable on the real line for all $h\in\tvs^{*}$. We say that an element $a\in\tvs$ is the 
expectation of $X\in\tvs$ if 
\begin{equation*}
\E(f,X)=\langle f, a\rangle,\qquad\text{for all }f\in\tvs^{*}.
\end{equation*}
Also a linear and positive definite operator $K:\tvs^{*}\longrightarrow \tvs$ 
is called the covariance operator (e.g. covariance
matrix in the finite dimensional case) if
\begin{equation*}
cov(\langle f_{1},X\rangle,\langle f_{2},X\rangle)=\langle f_{1},Kf_{2}\rangle,
\end{equation*}
for all $f_{1},f_{2}\in\tvs^{*}$. Then we say that $X$ is distributed as 
$\mathcal{N}(a,K)$. It is worth mentioning
that given a covariance operator $L$ and an element $b\in\tvs$ the distribution $\mathcal{N}(b,L)$
does not always exist. But if it does exist, the  Gaussian measure $\mathcal{N}(a,K)$, is completely
identified with $a$ and $K$.
\newline

%%%%%%%%%%%%%%%%%%%%%%%Think about this bit %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%with the construction of a rigorous framework that allows us to talk about gaussian distributions in 
%function spaces we can see why once the covariance function and the mean function are defined then we 
%have created a Gaussian distribution over some function of spaces and why the nature of the function
%space depends heavily on the regularity properties of the covariance kernel. 

%%%%%%%%%%%%%%%%%This is also you need to think about %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%What is the connection between K and a covariance function k(x,x')?%%%

%In this work we are going to be mainly concerned to work with kernels that are at least continuous
%(For example the SE kernel in equation (\ref{eqnsquareexponential}) is $C^{\infty}$). 
As an example consider the  $\tvs=C(T)$ where 
$T$ is compact subset of $\mathbb{R}^{n}$. This is the  space of real valued continuous functions 
on
$T$. This  is a Banach
space with the norm \cite{bressan1900lecture}
\begin{equation*}
\|h\|=\max_{x\in T}|h(x)|.
\end{equation*}
The dual space of $\tvs$ is given by $\tvs^{*}=\mathbb{M}(T)$ the set of signed measures defined on 
the Borel $\sigma-$ algebra of  $T$. In this 
case the duality pairing is given by 
\begin{equation*}
\langle\mu,g \rangle=\int_{T}gd\mu.
\end{equation*}
A GP,  $\{g(t)\}_{t\in T}$ (see definition \ref{dfnGP}) with mean function $m(t)$ and 
covariance kernel $k(t,t')$, can be thought of as a Gaussian measure $\mathcal{N}(m,K)$
where
\cite{lifshits2012lectures} 
\begin{eqnarray*}
\E(f)=m\in\mathbb{C}(T), \\
(K\nu)(t)=\int_{T}k(t,t')d\nu(t'),\qquad\text{for }\nu\in\mathbb{M}(T).
\end{eqnarray*}

The above example shows the connection between GPs and distribution over function spaces. More
precisely how it is connected to Gaussian measures in function spaces. Now we 
explain how to use GPs in a practice.

Assume  we have some  data $\{(\textbf{x}_{i},y_{i})\}_{i=1}^{m}\subset\mathbb{R}^{n}\times\mathbb{R}$ 
 from an expensive function  $M(\cdot)$, 
, where $M(\textbf{x}_{i})=y_{i}$. The set $\{(\textbf{x}_{i},y_{i})\}_{i=1}^{m}$ is called
\textit{training set}. For
simplicity we assume no trend in the \textit{training outputs} $\{y_{i}\}_{i=1}^{m}$. Given the training set
we would like to infer  possible values of $M(\cdot)$ on another set of points 
$\{\textbf{x}_{j}^{*}\}_{j=1}^{k}$. This set of points  is known as \textit{test set}.
For this purpose we construct an emulator $\widehat{M}(\cdot)$ (see introduction to section 2.1).
To construct $\widehat{M}(\cdot)$  we  start considering the GP denoted by $\{f(\textbf{x})\}_{\x\in dom(M)}$
 where $dom(M)$ 
is  the domain of $M(\cdot)$.
 By
Definition \ref{dfnGP}, the random vectors
\begin{eqnarray*}
\textbf{f}=\begin{bmatrix}f(\textbf{x}_{1}) & \ldots & f(\textbf{x}_{m}) \end{bmatrix}^{T}, \\
\textbf{f}^{*}=\begin{bmatrix}f(\textbf{x}_{1}^{*}) & \ldots & f(\textbf{x}_{l}^{*}) \end{bmatrix}^{T},
\end{eqnarray*}
are  jointly Gaussian, i.e. 
\begin{equation}\label{eqnconditional}
\begin{bmatrix}
\textbf{f} \\
\textbf{f}^{*}
\end{bmatrix}\sim\mathscr{N}\left(0,\begin{bmatrix} K(X,X) & K(X,X^{*}) \\
						    K(X^{*},X) & K(X^{*},X^{*}) \end{bmatrix}
\right),
\end{equation}	
where the zero mean models the assumption of no trend in the training output $\{y_{i}\}_{i=1}^{m}$.
Here
$(K(X,X))_{ij}=cov(f(\x_{i}),f(\x_{j})), K(X,X^{*})_{ij}=cov(f(\textbf{x}_{i}),f(\x_{j}^{*}))$ and so on.


By the requirements of Defintion \ref{dfnEmulator},
 the realization of the random vector $\textbf{f}$ is known and is equal to $[y_{1},\ldots,y_{m}]^{T}$.  
and we want to  infer  the vector $\textbf{f}_{*}$.
This can be achieved by obtaining the distribution of $\textbf{f}_{*}|\textbf{f}$. By well known properties
of the multivariate Gaussian distribution we  obtain  \cite{lifshits2013gaussian}
\begin{equation}\label{eqnformulameancovariance}
\textbf{f}^{*}|\textbf{f}\sim\mathscr{N}(\langle\textbf{f}\rangle,\Sigma),
\end{equation}
where
\begin{align*}
&\langle\textbf{f}\rangle=K(X^{*},X)K(X,X)^{-1}\textbf{f}\\
&\Sigma=K(X^{*},X^{*})-K(X^{*},X)K(X,X)^{-1}K(X,X^{*}).
\end{align*}
Note that  if in the above equations, we only consider just one  test point, $\x^{*}$ and
we take the limit as $\x^{*}$ approaches  to the training input $\x_{j}$,
 the matrix
$K(\x^{*},X)$ is now a vector and  converges to  $K(\x_{j},X)$. In this case, it is not hard 
to see that the mean
would be given by 
\begin{equation}\label{eqnExactPrediction}
K(\x_{j},X)K(X,X)^{-1}\textbf{f}=y_{j}.
\end{equation} 
The covariance matrix would 
be an scalar  that tends to zero as $\x^{*}\rightarrow \x$. The interpretation is that 
at a training input $\x_{j}$ the prediction is exactly the  corresponding training output $y_{j}$. 
For a point $\textbf{x}^{*}$ that is not part of the training set, with $95\%$ of confidence we have
\begin{equation}\label{eqnConfidence}
M(\x^{*})\in [\langle f \rangle(\x^{*})-2\sigma,\langle f\rangle(\x^{*})+2\sigma],
\end{equation}
where
\begin{align*}
&\langle f\rangle(\x^{*})=K(\textbf{x}^{*},X)K(X,X)^{-1}\textbf{f}&&\text{(Mean at point $\x^{*}$)}  \\
&\sigma^{2}=K(\textbf{x}^{*},\textbf{x}^{*})-
K(\textbf{x}^{*},X)K(X,X)^{-1}K(X,\textbf{x}^{*}) &&\text{(Variance at point $\x^{*}$)}.
\end{align*}
Equations (\ref{eqnExactPrediction}) and (\ref{eqnConfidence})  show that if we define 
\begin{equation}\label{eqnDefEmulator}
\widehat{M}(\x^{*}):=\langle f\rangle(\x^{*}), 
\end{equation}
then $\widehat{M}(\cdot)$ satisfies the 
conditions for an emulator as in Definition \ref{dfnEmulator}.

In Figure \ref{figChp2}, it is shown an example that summarizes the discussion above.
We consider the problem of emulating the model $M(x)=\cos(2\pi x)$ (dashed-dotted line)
having five training points (black dots). The 95\% confidence region (dashed lines)
shows that in the training input $\x_{j}$  the variance is zero  and $\widehat{M}(\x_{j})=y_{i}$, 
as predicted by equation (\ref{eqnExactPrediction}).
\newline

The covariance kernel is the quantity that defines the mean and covariance for
the Gaussian distribution obtained when we look at finitely many random variables in 
a Gaussian Process. Therefore choosing it
is a crucial step in the fitting process. We now proceed to briefly talk about the properties
of kernels and how to choose them depending on the data and the smooth properties we are looking
for in the emulation process. 

\subsubsection*{Covariance Kernels}
The covariance kernel cannot be any arbitrary function $k(\x,\x^{*})$. To see why, consider  the
matrix in  equation (\ref{eqnconditional}) given by
\begin{equation*}
C:=\begin{bmatrix} K(X,X) & K(X,X^{*}) \\
 K(X^{*},X) & K(X^{*},X^{*}) \end{bmatrix}.
\end{equation*}


This is the covariance matrix of a multivariate Gaussian distribution and is obtained by evaluating
the covariance kernel at different points. The matrix $C$ has to be  symmetric and  positive definite 
for any set of training and test inputs. This implies that the covariance kernel has to be symmetric,
that is, for all $\x,\x'$ in its domain we have
\begin{equation*}
k(\x,\x')=k(\x',\x).
\end{equation*}
We also need that, for  any set of inputs $\{\x_{i}\}_{i=1}^{n}$  the Gram  matrix defined by 
$K_{jk}:=k(\x_{j},\x_{k})$, to be positive definite. If also $k$ is just a function of $\x-\x'$,
then $k(\cdot,\cdot)$ is said to be $\textit{stationary}$.

To understand the role of the covariance kernel in the continuity and differentiability
 of the mean function, let us
define some concepts first. 
\begin{definition}
Let $\y,\x_{1},\x_{2},\ldots$ be a sequence of points in $\mathbb{R}^{n}$, such that 
\begin{equation*}
\|\x_{n}-\y\|_{2}\rightarrow 0\qquad\text{as }n\rightarrow\infty.
\end{equation*}
Then the collection of real valued random variables $\{f(\x)\}$ defined in a probability space
$(\Omega,\mathscr{F},\p)$ are say to be continuous in the mean
square at the point $\y$ if 
\begin{equation*}
\E(|f(\x_{n})-f(\y)|^{2})\rightarrow 0\qquad\text{as } n\rightarrow\infty,
\end{equation*}
where
\begin{equation*}
\E(f(x)):=\int_{\Omega}f(x)d\p.
\end{equation*}
\end{definition}
We also have a definition for differentiability
\begin{definition}
The mean square derivative of the  collection $\{f(\x)\}$  it the $i-th$ direction  at a point $y$ is
\begin{equation*}
\frac{\partial f(\y)}{\partial x_{i}}=
\lim_{h\rightarrow 0}\E\left(\left|\frac{f(\y+h\textbf{e}_{i})-f(\y)}{h}\right|^{2}\right),
\end{equation*}
where $\textbf{e}_{i}$ is the $i$-th canonical vector of the standard basis in $\mathbb{R}^{n}$.
The mean square $n$-th derivative is given by 
\begin{equation*}
\frac{\partial^{n} f(\y)}{\partial x_{i}^{n}}=
\lim_{h\rightarrow 0}\E\left(\left|\frac{\frac{\partial^{n-1}f(\y+h\textbf{e}_{i})}{\partial x_{i}^{n-1}}-
\frac{\partial^{n-1}f(\y)}{\partial x_{i}^{n-1}}}{h}\right|^{2}\right),
\end{equation*}
whenever the limit Exists.
\end{definition}


For Gaussian processes $\{f(\x)\}$ with stationary covariance kernel it can be showed that 
the process is continuous in the mean at a point $\y$ if and only if $k$ is continuous at $(\y,\y)$. 
Also the kernel function for the $n$-th derivative is given by \cite{adlergeometry}
\begin{equation*}
\frac{\partial^{2n}k(\x,\x')}{\partial^{2}x_{1}\ldots\partial^{2}x_{m}'}.
\end{equation*}
Therefore the continuity and differentiability properties of the mean function in a Gaussian process
depends exclusively in the continuity and differentiability properties of the covariance kernel.


Another important aspect of covariance kernels is that they are  defined in terms of parameters. 
The way we choose the values of these parameters in practice, is based on the data
we are analyzing. To see how this works, let us return to the problem of of approximating $M(\cdot)$
by $\widehat{M}(\cdot)$ using Gaussian processes. Let   $k(x,x';\theta)$ be the covariance
kernel for the GP that depends on the parameter $\theta$ 
($\theta$ could be a scalar, vector, etc.). In this case to predict the output
$\y^{*}=\{M(\x_{1}^{*}),\ldots M(\x_{m}^{*})\}$ given the training set $\{(\x_{i},y_{i})\}_{i=1}^{m}$, 
we can try different approaches. On of the most common is maximum likelihood optimization (MLE). 
Mathematically, we pick a parameter $\hat{\theta}$ such that
\begin{equation*}
\hat{\theta}=\argmax_{\theta}\p(\y^{*}|\{(\x_{i},y_{i})\}_{i=1}^{m},\theta).
\end{equation*}
By Definition \ref{dfnGP} we know that the conditional probability for $\y^{*}$ has to be distributed as
a multivariate Gaussian distribution. More precisely

\begin{equation}\label{eqnlikelihoodExponential}
p(\y^{*}|\{(\x_{i},y_{i})\}_{i=1}^{m},\theta)=\frac{1}{(2\pi)^{\frac{m}{2}}det(K_{\y^{*}}(\theta))^{\frac{1}{2}}}
e^{-\frac{1}{2}(\y^{*T}K_{\y^{*}}(\theta)^{-1}\y^{*})}.
\end{equation}
Where $K_{\y^{*}}(\theta)$ is the matrix $K(X,X)$ in equation (\ref{eqnconditional}). 
To find the value of $\hat{\theta}$  We have to maximize (\ref{eqnlikelihoodExponential})
with respect to $\theta$.
This goal is unchanged if we take logarithm on  both sides and minimize the following
function instead\footnote{The reason to do this is because most
software packages for optimization, search for the minimum not the maximum.}


\begin{equation}\label{eqnloglikelihood}
L(\theta)=-\log(p(\y^{*}|\{(\x_{i},\y_{i})\}_{i=1}^{m},\theta))=\frac{1}{2}\y^{*T}K_{\y^{*}}(\theta)^{-1}\y^{*}+
\frac{1}{2}\log|K_{\y^{*}}(\theta)|.
\end{equation}

A minimizer of $L(\theta)$   gives  a possible value for $\hat{\theta}$
that explains the best the data $\y^{*}$ given the training set $\{\x_{i},y_{i}\}_{i=1}^{m}$.  
Another common way to tune in the parameters
is using  $K$-fold cross validation. We will not use this approach here, the interested
reader is referred to \cite{murphy2012machine} for details.
\newline

So far we have not discussed  how to choose the training inputs $\{\x_{i}\}_{i=1}^{m}$. 
Clearly this choice has a profound  impact in the quality of the accuracy of the emulator.
To see this, let us assume that the function $M(\cdot)$ is supported in $[0,1]$ and we  have
computational resources to calculate the output of only five training
points. If we pick the points $\{0,0.1,0.2,0.3,1\}$ the interpolation error of the emulator
$\widehat{M}(\cdot)$  for points between $0.3$ and $1$, 
is going to be big, compared to the error associated with the partition $\{0,0.25,0.5,0.75,1\}$ as
shown below
\begin{figure}[H]
\raggedleft
\includegraphics[scale=0.33]{./FigChap2/partitionComparison}
\caption{Comparison between the approximation quality of the emulator $\widehat{M}$ for 
for the model $M(x):=\cos(2\pi x)$ in the interval $[0,1]$ for two different partitions. 
On the left, the emulation is performed in the partition $\{0,0.25,0.5,0.75,1\}$. On
the right in the partition $\{0,0.1,0.2,0.3,1\}$.}
\label{figChp2}
\end{figure}
 




Ideally we would like to pick as many training points as possible to make the fitting better, 
but picking too many points
to create the training set, might result in a very high computational demand. On the other hand if we pick up
just few points to create the training set, then it is possible to end up with unreliable predictions. 
Thus we need a systematic way to choose  the training points. One strategy is to  
 fill as much of the space as possible given a fix number (possibly small) of  training points. 
This can be accomplish
through    space filling designs which we will now discuss. 
\newline

%%%Sensitivity. The first paragraph should be relocated
\subsection{Design of Experiments }

%Besides uncertainty there is another very important concept: sensitivity. When looking at a  model's performance
%it is critical to assess how changes or uncertainties 
% in the input $x$ affect the output $y$. Therefore if we assess sensitivity
%of the model we can assess uncertainty of the outputs. One more reason one might be interest in performing
%a sensitivity analysis is to detect what variables are relevant and what variables are not, allowing to reduce
%the dimensionality of the problem .

% To interpolate the data obtained from evaluating the computationally expensive function
%$M(\cdot)$ using GPs, we need to decide in how many different points are we going to evaluate $M(\cdot)$. 
%As mentioned in the previous section this is a very delicate issue since we need to find 
%the right balance between
%the number of possible evaluations of $M(\cdot)$ given time, computational budget 
% and a good spread of data points in the space to get a good
%fit to the model.

We assume there is a fixed computational budget. In this case we need to decide how
to choose the training inputs $\{\x_{j}\}_{j=1}^{m}$ to obtain reliable predictions 
of the emulator for points
different than the training points. As shown in Figure \ref{figChp2}, the quality
of the emulation depends heavily on the distribution of the training inputs. 
Intuitively we want to spread the training inputs as much as possible in the
parameter space while covering  as much space as possible. 
Distributions of points that achieve this are called \textit{space filling designs}.
\newline
 
Given an set $T\subset\mathbb{R}^{n}$, there are several ways to create space filling designs. 
In this work we are going to focus on maximin designs
\cite{johnson1990minimax}. We note that there are other ways to obtain space filling
designs and we refer to the reader to  \cite{pronzato2012design}. Consider a metric space $(T,d)$ (e.g.
$T\subset\mathbb{R}^{n}$, compact and $d$ the Euclidean distance) and a subset $S$ of $T$, 
with finite (fixed) cardinality, say $|S|=n$.
A maximin distance design $S^{o}$ is a collection of points of $T$  such that
\begin{equation*}
\max_{S\subset T,\text{ }|S|=n}\min_{s,s'\in S}d(s,s')=\min_{s,s'\in S^{o}}d(s,s')=d^{o}.
\end{equation*}
That is, we are looking for a set $S^{o}$ of cardinality $n$ that maximizes the minimum distance among 
its elements. As an example consider $T=[0,1]^{3}$, the unit cube in $\mathbb{R}^{3}$ and $n=8$. In 
this case the design that maximizes the minimum distance among its elements is given by choosing
 the 8 vertices of the cube. Or as shown if Figure \ref{figChp2}, right, if $T=[0,1]$ and $n=5$, 
the maximin design is given by a uniform partition  of the set $T$.


The problem of finding
the optimal  maximin design is difficult to solve. In practice we use computational tools
to find a design that is close to optimal.  Different kind of algorithms can be used for the optimization
of the design, such as genetic algorithms, simulated annealing, particle swarm, etc. A survey
on the subject  can be found in 
\cite{viana2010algorithm}. In Chapter 4 we will see how  the particle swarm algorithm can be used to 
create a maximin design in a five dimensional parameter space.

To conclude this section, we note that there is a conection between maximin designs and Gaussian processes. 
Consider a
GP $\{f(x)\}_{x\in T}$. If we fix $S=\{s_{1},\ldots,s_{n}\}\subset T$  and consider the random vector
\begin{equation*}
\textbf{f}=[f(s_{1}),\ldots,f(s_{n})],
\end{equation*}
where $\textbf{f}$ is assumed to be jointly Gaussian. Let $K_{s}$ be 
the correlation matrix for the probability distribution of $\textbf{f}$. Then it can be shown
that the minimax design minimizes the quantity 
\begin{equation*}
D(S)=-det(K_{s}).
\end{equation*}
This matrix is the same as the covariance matrix in equation (\ref{eqnconditional}).
A survey on the theory behind maximin distance designs can be found in \cite{johnson1990minimax}.
\newline


%ince the covariance matrix is positive definite (hence the correlation matrix is also positive definite)
%, then $det(K_{s})>0$. By minimizing the  negative of the determinant  we are maximizing
% the determinant. This is achieved when the column vectors of a matrix
%are orthogonal. 


\subsection{Sensitivity Analysis}


In general having an space filling design for the training input, permits to create an
emulator $\widehat{M}(\cdot)$ that closely approximates $M(\cdot)$  over its whole domain. 
By closely we mean a tolerable uncertainty in the output of the emulator 
for all points in the domain (see Figure \ref{figChp2}).
%Let us suppose that we have a good space filling design, we can construct a good GP, in the sense that 
%the uncertainty in the interpolation is less compared to the interpolation error when
%using other space filling design. 
%then we have a good fit when using gps to interpolate  the 
%points we want to get information about. 
If we have a reliable fitting we can confidently assess what arguments in the model $M(\cdot)$
are relevant and which ones are not.
This allows to approximate  the model  with a simpler one.
For example, if our model is given by 
\begin{equation*}
M(x_{1},x_{2},x_{3})=x_{1}+x_{2}+10^{-8}x_{3},\qquad(x_{1},x_{2},x_{3})\in  T=[0,1]^{3}.
\end{equation*}
Clearly the variable $x_{3}$ is not as relevant as $x_{1}$and $x_{2}$. We need to
formalize in what sense $x_{3}$ is irrelevant. One way to achieve this is by doing a 
sensitivity analysis. In summary, the goal of 
sensitivity analysis is to assess how
the output of a function $M(\cdot)$ depends on variations of its arguments. There is
a great number of methods to do a sensitivity analysis, such as adjoint methods, local
methods, variance based methods, etc. to name a few. The difference of each of these
methods is how they measure the importance of each variable. For example in local methods,
the sensitivity at a point in a given direction is the slope of the function, whereas in
variance based method what matters is how large is the area under the curve when
fixing all parameters but one.
For a survey of techniques in sensitivity analysis, 
the reader is referred to \cite{saltelli2000sensitivity}. In this work we  use 
variance-based Monte Carlo methods (VBMCM) described in \cite{sobol1993sensitivity}.
The idea of  VBMCMs is to use the variance produced by  the inputs of a function as an indicator of 
their importance. More precisely we are going to use the method of Sobol'. We now explain
the main ideas behind this method.


The functions of interest in this work have compact support. This implies that
without loss of generality we may assume that  the domain of these functions 
is the $n$-dimensional unit cube $\Omega^{n}$. Let us consider a generic
square integrable function
\begin{equation*}
\varphi:\Omega^{n}\rightarrow\mathbb{R}.
\end{equation*}
We start by decomposing $\varphi$ as 
\begin{equation*}
\varphi(x_{1},\ldots,x_{n})=\varphi_{0}+\sum_{k=1}^{n}\varphi_{k}(x_{k})+
\sum_{1\leq k< l\leq n}\varphi_{kl}(x_{k},x_{l})+\ldots+
\varphi_{1,2,\ldots,n}(x_{1},\ldots,x_{n}).
\end{equation*}
This decomposition is not unique, but it can be shown that if each term $\varphi_{i_{1},\ldots,i_{j}}$
in the expansion satisfy

\begin{equation}\label{eqnSobolCond1}
\int_{[0,1]}\varphi_{i_{1},\ldots,i_{j}}dx_{i_{k}}=0\qquad\text{if }  i_{k}\in \{i_{1},\ldots,i_{j}\},
\end{equation}
then the decomposition is unique and all terms in the expansion are orthogonal in $L^{2}(\Omega^{k})$. To 
see the orthogonality property, 
we may  consider the functions $g=\varphi_{i_{1},\ldots,i_{j}}$ and $h=\varphi_{l_{1},\ldots,l_{k}}$ 
with arbitrary indices $(i_{1},\ldots,i_{j})\neq(l_{i},\ldots,l_{k})$. Without 
loss of generality we may  assume $i_{1}\neq l_{1}$. In this case we have
%by Fubinni's theorem \cite{lerner2014course} we may conclude that functions with different subindices are 
% pairwise orthogonal in $\Omega^{n}$ with the standard inner product of $\mathbb{R}^{n}$\cite{bressan1900lecture}. 
%To see this, without loss of generality
%we may  consider the functions $g=\varphi_{i_{1},\ldots,i_{j}}$ and $h=\varphi_{l_{1},\ldots,l_{k}}$ 
%with $(i_{1},\ldots,i_{j})\neq(l_{i},\ldots,l_{k})$, with $i_{1}\neq l_{1}$. In this case we have
\begin{equation*}
\langle g,h\rangle=\int_{[0,1]}\ldots\int_{[0,1]}\underbrace{\left(\int_{[0,1]}\varphi_{i_{1},
\ldots,i_{j}}dx_{i_{1}}\right)}_{\text{$=0$ by (\ref{eqnSobolCond1})}}
\left(\int_{[0,1]}\varphi_{l_{1},\ldots,l_{k}}dx_{l_{1}}\right)dx_{\sim i_{1},l_{1}}=0,
\end{equation*}
where we used Fubinni's theorem to split the integrals \cite{lerner2014course}. The symbols to the right of $\sim$ 
represent the variables omitted in the integration.

Another consequence of  (\ref{eqnSobolCond1}) is 
\begin{eqnarray*}
\int_{\Omega^{n}}\varphi dx=\varphi_{0}.
\end{eqnarray*}

This allows us to find  the other functions in the decomposition recursively,
given $\varphi_{0}$. For example 
for $i\in \{1,\ldots,n\}$ we have
\begin{equation*}
\varphi_{i}(x_{i})=-\varphi_{0}+\int_{[0,1]^{n-1}}\varphi(x)dx_{\sim i}.
\end{equation*}
Having $\varphi_{i}(x_{i})$ we can proceed to find $\varphi_{ij}(x_{i},x_{j})$ using
\begin{equation*}
\varphi_{ij}(x_{i},x_{j})=-\varphi_{0}-\varphi_{i}(x_{i})-\varphi_{j}(x_{j})+
\int_{\Omega^{n-2}}\varphi(x)dx_{\sim ij}.
\end{equation*}

By knowing all of
the functions in the decomposition of $\varphi$ we are able  to assess how each variable 
affects the output of $\varphi$ in the following way: the total variance $D$ of $\varphi$ is defined as
\begin{equation*}
D=\int_{\Omega^{n}}\varphi^{2}(x)dx-\varphi_{0}^{2}.
\end{equation*}
Similarly we can compute the partial variances as
\begin{equation*}
D_{i_{1},\ldots,i_{s}}=\int_{[0,1]^{n-1}}\varphi^{2}_{i_{1},\ldots,i_{s}}dx_{i_{1}}\ldots dx_{i_{s}}.
\end{equation*}
With these variances we define the $s$-th order  Sobol index  
\begin{equation*} 
S_{i_{1},\ldots,i_{s}}=\frac{D_{i_{1},\ldots,i_{s}}}{D}\qquad\text{(Sobol' Index of Order s)},
\end{equation*}
which is a measure of the contribution of the variables $x_{i_{1}},\ldots,x_{i_{s}}$ to the total variance $D$.
If we want to know the separate effect  of each variable
$x_{1},\ldots,x_{n}$ in the total variance $D$, we look at
the first order Sobol indices $S_{1},\ldots,S_{n}$ given by
\begin{equation*}
S_{i}=\frac{D_{i}}{D},\qquad\text{for }i=1,\ldots,n.
\end{equation*}

Finally if we want to assess the full effect of a  variable  in the total variance $D$, 
we calculate a quantity known 
as the total effect index. For example if we want to calculate the total effect index
for the variable $x_{i}$ we would do so by calculating
\begin{equation*}
S_{i}+S_{i1}+S_{i2}+\ldots+S_{i12}+S_{i13}+\ldots+S_{12\ldots,i,\ldots, n}.
\end{equation*}

Note that  to calculate each of the Sobol indices, it is necessary to do 
high dimensional integrals. Therefore integration using quadratures is not possible.
It is necessary to resort to other numerical integration techniques. A common
tool to perform high dimensional integrals is known as Monte Carlo integration. We will not
go into details of Monte Carlo integration in this chapter, we postpone them for Chapter 3.
What is important at this time is that to apply Monte Carlo integration, it is necessary to 
evaluate the integrand a high number of times at different points in its domain. If the 
integrand is the expensive model $M(\cdot)$, then the computational cost of estimating
the Sobol' indices is prohibitive. If instead we calculate the Sobol' indices 
of the emulator $\widehat{M}(\cdot)$, we can use them as an approximation for the Sobol'
indices of $M(\cdot)$. In this way we can estimate what arguments of the model are 
relevant and what arguments are not. This will allow us to reduce the complexity of the
model.

In the next chapter we are going to show how to the theory explained in  this chapter
can be used in a practical setting using a toy problem. In Chapter 4 we 
proceed to apply the tools developed here to the problem explained in Chapter 1.


%%Talking about R packages
%\newpage
%\subsection{R packages}
%In this work we used two different R packages. One to do the fitting with GPs (DiceKriging) and the other to do 
%a sensitivity analysis using Sobol Indices (Sensitivity). We are going to briefly describe both of this packages.
%
%\subsubsection{Package: DiceKriging}
%According the description of the package (http://dice.emse.fr/) it is used for Estimation, validation and 
%prediction of GP models.
%
%The way this package works is as follows. First it creates an element of the class `km' by receiving 
%as an input a trending formula, the set of training points $(x_{i},f_{i})$ and a choice 
%of a covariance kernel. The kernels available are: Gauss, Exponential, Matern $\frac{3}{2}$
%,Matern $\frac{5}{2}$ and power exponential. It is also possible to work with tailored covariance
%kernels but we won't explore that possibility. Once the `km' object is created we can do 
%predictions on test points $x^{*}$ 
%by using the function predict. Predict takes as an input a km object, the set of test points and 
%some other optional parameters. Gives as an output an R list that contains the estimation of $f(x^{*})$
%using the mean of the $GP$ and the lower and upper 95\% confidence interval using the 
%covariance matrix (see equation (\ref{eqnformulameancovariance})).
%One of the nice feature that the DiceKriging package has is that once you choose a kernel, you don't
%have to set the parameters of the kernel chosen. Using an optimization routine the function
%predict chooses the best combination
%of parameters through a Maximum Likelihood Optimization \cite{dupuy2015dicedesign} (see \ref{eqnloglikelihood}).
%
%
%\subsubsection{Package: Sensitivity}
%The main function we used was the function SobolGP. This function takes as its main   input an object 
%from the class `km' A matrix representing a sample of random points in the domain of the function $f$
%we want to calculate its sensitivity (this function $f$ was previously 'fitted' by the function
%km in package DiceKriging) and the main output are two lists. One lists that contains 
%all the results for the GP-based sensitivity analysis for the main effect and one list with the 
%results for the GP-based sensitivity analysis for the total effects.
%
% 
%
%For the next chapter we are going to explain how to use in a toy problem all of this tools explained in this 
%chapter, so for chapter four we can focus on the results instead on how we applied what was explained here. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Toy Problem: How Theory Works in Practice}

In the previous chapter we reviewed some  of the theoretical and computational tools needed to solve
a Bayesian inverse problem. In this chapter
we are going to present  a toy problem to illustrate how the theory  can be applied in practice.
We begin by considering the forward problem, given by the following partial differential equation (PDE).

\begin{equation}\label{eqntoyproblem}
\left\{
	\begin{array}{ll}
		\Delta u=e^{-b\|\x\|_{2}}, &\mbox{for } x\in\Omega=[0,1]\times [0,1]\subset\mathbb{R}^{2}, \\
		u=0, & \mbox{for } x\in\partial\Omega,
	\end{array}
\right.
\end{equation} 
where $b$ is some real positive parameter. The 
function $u$ represents the mathematical approximation of  a quantity with a physical interpretation  $\tilde{u}$. The  behavior
of $\tilde{u}$ is assumed to be    modeled by equation (\ref{eqntoyproblem}).

In Chapter 2 Section 2.1, we explained how to build an emulator $\hat{M}(\cdot)$  that approximates
the output $y$  of a computationally expensive function  $M(\cdot)$ at a point  in its domain. 
In  this chapter, the function $M(\cdot)$ takes as input a point  $(\textbf{x},b)\in\Omega\times(0,\infty)$. The
output is the value of the solution $u$ at that 
point, i.e. $u(\textbf{x};b)=M(\textbf{x},b)$. Now we proceed to explain the associated inverse problem and  how we are going to construct $\hat{M}(\cdot)$.  

Assume that we have ten experimental measurements 
of $\tilde{u}$. These measurements were taken  at the points $P:=\{\x_{1},\x_{2},\ldots,\x_{10}\}\subset\Omega$. 
That is, we know the vector of measurements 
$\textbf{y}=(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$.
We want to estimate the value of $b$ that explains  the experimental data $\textbf{y}$ the best. 
This is our inverse problem. 
A simple approach to estimate $b$ 
would be to solve equation (\ref{eqntoyproblem}) for a big number of values $b$ in the interval $(0,L]$ where $L$ 
is chosen in a manner that there exists a $b^{*}\in (0,L]$ such that the set 
$\{u(\x_{1};b^{*}),\ldots,u(\x_{10};b^{*})\}$
has `small' discrepancy with the experimental data $\y$. 

Let us assume that solving
equation (\ref{eqntoyproblem}) is computationally expensive and repeating the calculation for a big range of 
different values of $b$
is not feasible. Therefore we need to construct an emulator $\widehat{u}(\cdot)$ that approximates $u(\cdot)$. 
The way we are going to construct $\widehat{u}(\cdot)$ is as follows: for a fixed $\x$ we solve equation 
(\ref{eqntoyproblem}) for   number $n$ of different values of  $b$. We pick the value of $n$ in a way
that the computational cost of computing (\ref{eqntoyproblem}) $n$ times, does not exceed our
computational and time budget. Then use the data $\{b_{j},u(\x,b_{j})\}_{j=1}^{n}$  as a 
training set to create a Gaussian process, as explained in Chapter 2, Section 2.1.1. Finally
for any value $\tilde{b}$ we use the mean of the Gaussian process at that point as $\widehat{u}(\x,\tilde{b})$.
An sketch of the result for approximating a model $u(\x;\cdot)$ with an emulator is shown
in Figure \ref{figGPCreation}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{./FigChap3/emulatorApproximation}
\caption{Approximation of a model $u(\x;\cdot)$ by the mean of a Gaussian process trained
with six  different  outputs from it. The mean of the Gaussian process at a point $\tilde{b}$ is taken
as the value $\widehat{u}(\x;\tilde{b})$.}
\label{figGPCreation}
\end{figure}

For clarity in the exposition of the material, in the table below we summarize the notation 
we are going to use throughout the rest of the chapter.




%Finally use the emulator
%$\hat{M}(\cdot)$ to predict the output of $M(\cdot)$ for as many different values of $b$ as possible. 
%The value of the emulator at the point $(\x,b)$  is going to be denoted by $\hat{u}(\x;b)$. The following
%table summarizes the notation that is going to be used from now on in this Chapter.

%\begin{table}[H]
%\centering
%\begin{tabular}{|c|c|}
%\hline 
%Symbol & Meaning \tabularnewline 
%\hline 
%\hline
%\hline 
%$\tilde{u}(\x;b)$ & \pbox{7cm}{Value of the physical variable at the point $\x$
%with parameter $b$.\\} \tabularnewline 
%\hline 
%\hline
%$u(\x;b)$ & \pbox{7cm}{Numerical solution of equation (\ref{eqntoyproblem})
%at $\x$ with parameter $b$.\\} \tabularnewline
%\hline
%\hline 
%$\hat{u}(\x;b)$ & \pbox{7cm}{Value of the interpolation of the emulator $\hat{M}(\cdot)$ at the point $\x$ with parameter
%$b$\\}.  \tabularnewline
%\hline
%\hline 
%$P:=\{\x_{1},\ldots,\x_{10}\}$ & \pbox{7cm}{Points where the experimental measurements were taken\\}.  \tabularnewline
%\hline
%\hline 
%$\y:=(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$ & \pbox{7cm}{Values of the experimental measurements for the variable $\tilde{u}$\\}.  \tabularnewline
%\hline
%\end{tabular}
%
%\caption{Summary of symbols used in Chapter 3.}
%\label{tabSymboltable}
%\end{table}
\newpage
We want to estimate the value of $b$ that explains the best the experimental data $\y$. 
To incorporate $\y$ into the inference, 
we can use Bayes rule and estimate the posterior distribution for $b$ as

\begin{equation} \label{eqnpropto}
\post(b|\y)=\frac{\like(\y|b)\prior(b)}{\p(\y)}.
\end{equation}

Having the posterior we can estimate $b$ using any of the point estimates given in equation (\ref{eqnpointestimates}) along
with the  uncertainty associated with the chosen estimate.

Before we proceed  to find the posterior distribution for $b$, let us explain how we are going to generate the experimental measurements $\y$. 
Assume that the true value of $b$ is $0,925$. Then we solve equation (\ref{eqntoyproblem})
using this value of $b$. Next we pick  ten points at random  and save the value of the numerical 
solution $u$ at those location (see Figure \ref{figsolU}).  Finally we add  noise from
a normal distribution with mean $0$ and $\sigma=0.01$ to each  of the ten values. The resulting numbers obtained are what we use
as the experimental data $\y=(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$. The noise added to the data obtained from the
numerical  solution of equation
(\ref{eqntoyproblem}) plays the role of possible  errors in the experimental measurements plus inaccuracies of the 
model to describe the true behavior of $\tilde{u}$.




\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./FigChap3/solu}
\caption{Numerical solution of the system (\ref{eqntoyproblem}) using a five points stencil finite difference
approximation for the Laplacian. The mesh
size used in $x$ and $y$ was $0.01$. The value of the parameter $b$ was set at $0.925$. The black dots
in the plot represent the points used to generate the experimental data 
$(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$}
\label{figsolU}
\end{figure}
Now that we explained how to generate the data $\y$, we  continue with how to estimate $b$   using Bayes formula (\ref{eqnpropto}).
First we need to choose a prior distribution for $b$. For the sake of the example, let us assume that 
equation (\ref{eqntoyproblem}) describes a well known physical process and it is known that
the parameter $b$ cannot be greater than $2$. In this case one way to choose a prior distribution
for $b$ that does not assume any other knowledge than $b\in (0,2]$ is the \textit{uniform distribution}. 
With this distribution, given a Borel measurable set $A\subset(0,2]$, the probability that $b$ belongs to $A$ is given by
\begin{equation*}
\frac{1}{2}\int_{A}dx.
\end{equation*}
In this case we have 
\begin{equation}\label{eqnpriortoyproblem}
\prior(b)=\frac{1}{2}\textbf{1}_{(0,2]}(b),
\end{equation}
where $\textbf{1}_{(0,2]}$ is the indicator function of the set $(0,2]$. The indicator function for a Borel measurable set $C$ is
defined as
\begin{equation*}
\textbf{1}_{C}(y)=\left\{
	\begin{array}{ll}
		1 & \mbox{if }	y\in C\\
		0 & \mbox{if }   y\in C^{c}
	\end{array}
\right.
\end{equation*}

To calculate the likelihood we need to know how $b$ is connected with the data $\y$. The connection is given by 
equation (\ref{eqntoyproblem}). By solving explicitly this equation we can find a functional relation
between $u$ and $b$ for each one of the ten locations depicted in Figure \ref{figsolU}.
It is possible to explicitly solve equation (\ref{eqntoyproblem}). However
the relation between $u$ and $b$ is  given by an infinite Fourier series. Having a functional relation given
by an infinite series is often not very useful. Hence, the  approach we are going to use is the following: 
by assumption,
solving equation (\ref{eqntoyproblem}) is computationally expensive. Assume that given time and computational budget
we can solve the PDE for no more than 10 different values of $b$ (Having ten values of $b$ and ten points
where we measured $\tilde{u}$ is just coincidence). The idea is to use GPs as described
in Chapter 2 to interpolate for the values of $b\in (0,2]$ where we did not  solve equation (\ref{eqntoyproblem}). The value
of the interpolation done by the GP at a point is going to play the role of the output of the   emulator $\hat{M}(\cdot)$ at that point.
\newline

We need to choose ten values of $b$  to solve the PDE (\ref{eqntoyproblem}) in a way that the interpolation error for 
the other values of $b$ in the set $(0,2]$ is small compared to the error in the interpolation if we were to choose
a different set of ten values for $b$. We shall denote the points as $\{b_{1},\dots,b_{10}\}$. To choose the ten points 
we use a maximin design as explained in Chapter 2. In this case
it is straightforward to check that the way to choose the points that maximizes the minimum distance among the points
is by locating them in an equidistant manner i.e.
\begin{equation*}
\{b_{1}=0.2,b_{2}=0.4,\ldots,b_{10}=2\}.
\end{equation*}
This set gives the maximin design for our problem.
\newline 
Having the design, it is now possible to  create the set of training points for the GP as 
$\{b_{i},u(\x_{k},b_{i})\}_{i=1}^{10}$ for each of the 
$k=10$ sites where we obtained the experimental measurements $(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$.
 Using the training
points, we create the GP for each of the ten sites. For the interpolation we use as a test set
\begin{equation*}
\{0.01,0.02,\ldots,1.99,2\}.
\end{equation*} 
In Figure \ref{fignofitted} are plotted the training points, 
the GP regression over the test points, along with the true value of $b$
and the experimental measure $\tilde{u}(\x_{k};b)$ for each of the ten sites.



%
%We are ready to run the emulator $\hat{f}$ for these values of $b$, get a numerical value at
%the 10 points in the domain where the synthetic data were created (black dots in Figure \ref{figsolU})
%and use GPs to fill the missing information. Take into account that this process of `filling the blanks'
%has to be done in all of the 10 measurement points in the domain $\Omega$ of definition of the phyiscal model.
%
%In Figure \ref{fignofitted} we can see the results from running the emulator (black dots) compared
%with the experimental measurement for each of the 10 sites (black line).

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{./FigChap3/fitted}
\caption{Training points, GP regression, true value of $b$ and experimental measures for each one of the ten sites labeled
from 1 to 10 in Figure \ref{figsolU}}
\label{fignofitted}
\end{figure}

The intersection of the blue dotted line with the black dotted line in Figure \ref{fignofitted} represents, 
the value the numerical 
solution $u$  would attain  if it were to  perfectly model the physical variable $\tilde{u}$. 
Since we added noise to the values
$\{u(\x_{1};0.925),\ldots,u(\x_{10};0.925)\}$ we know that the value of $\tilde{u}$ has to be different 
from the value of $u$.
\newline

The solid line in Figure \ref{fignofitted} gives a functional relation between $\hat{u}$ and $b$ for each of the 
ten sites.
Let us denote $G_{k}(b):=\hat{u}(\x_{k};b)$ and $y_{k}=\tilde{u}(\x_{k};b)$ for $k=1,\ldots,10$. A possible 
functional relation
that connects these quantities is
\begin{equation}\label{eqnreal2interp}
y_{k}=G_{k}(b)+\epsilon_{k},\qquad\text{where } \epsilon_{k}\sim\mathcal{N}(0,\lambda^{2}),
\end{equation}
with $\lambda$ a positive number that models how much we believe the value of $\tilde{u}$ differs from the GP prediction $\hat{u}$. 
We chose the value $\lambda=5.4\times 10^{-3}$ to get a signal to noise ratio with $\y$ of 1:10.
If we define the vector  
$\textbf{G}(b)=(\hat{u}(\x_{1};b),\ldots,\hat{u}(\x_{10};b))$ and recalling the definition of $\y$ 
(see table \ref{tabSymboltable}), equation (\ref{eqnreal2interp}) can we written more compactly as
\begin{equation}\label{eqnvector2interp}
\textbf{y}=\textbf{G}(b)+\epsilon,\qquad\text{where }\epsilon\sim\mathcal{N}(0,\lambda^{2} I_{10\times 10}).
\end{equation}


Since the random vector $\epsilon$ has multivariate Gaussian distribution, we can use equation (\ref{eqnvector2interp})
to conclude \cite{Somersalo}
\begin{equation*}
\textbf{y}|b\sim \mathcal{N}(\textbf{G}(b),\lambda^{2} I_{10\times 10}),
\end{equation*}
Explicitly
\begin{equation}\label{eqnlikelihoodtoyproblem}
\p(\textbf{y}|b)\propto e^{-\frac{1}{2\lambda^{2}}\|\textbf{G}(b)-\textbf{y}\|_{2}^{2}},
\end{equation}
where the proportionality constant normalizes the distribution on the right hand side to one. Since
the denominator in Bayes rule in equation (\ref{eqnpropto}) is independent of $b$ and serves only 
as a normalization constant we can use equations (\ref{eqnpriortoyproblem}) and (\ref{eqnlikelihoodtoyproblem})  
to write 
\begin{equation}\label{eqnposteriorforb}
\post(b|\y)\propto\like(\y|b)\prior(b)\propto \textbf{1}_{(0,2]}(b)e^{-\frac{1}{2\lambda^{2}}\|\textbf{G}(b)-\textbf{y}\|_{2}^{2}}.
\end{equation}
An interpretation of this result is that before taking experimental measurements all we knew about the parameter $b$ was
that $b\in (0,2]$ after weighting this prior believe with the data $\y$ our current state of knowledge about the
parameter $b$ is encoded in the posterior distribution. Figure \ref{figlikeprior} plots this update in our knowledge about $b$.

%
%As we can see in Figure \ref{fignofitted}, the emulator sometimes overestimates the value of $b$ and sometimes
%underestimates it, this behaviour is expected. The hope is that this inaccuracies oscilate around the true
%value of $b$.
%
%Since we only have a limited number of prediction of the emulator for different values of $b$ (black points
%in Figure \ref{fignofitted}), we would like to extrapolate/interpolate those results to get
%more data and with that extra data, assess the value of $b$. As explained in Chapter 2, one very useful 
%way to obtain the extra data is through Gaussian processes. Using the language of the previous chapter
%what we want to do is, having the training points $\{(x_{i},f(x_{i})\}_{i=1}^{10}$ we want to predict 
%the value of different test points $x_{i}^{*}$. This prediction is shown as a red line in Figure
%\ref{fignofitted}.  The GP fit allows us to approxiamte as much value as we want, along with the uncertainty
%associated with the prediction. Having this data we can now proceed to use the Bayesian methodology.
%The idea goes as follows. if we denote the GP fit at at point $b$ as  $G(b)$, then we may assume
%an additive noise model for the output $y$ as
%\begin{equation}\label{eqnadditivenoise}
%y=G(b)+\vec{\epsilon}.
%\end{equation}
%$\vec{\epsilon}$ is a random vector distributed as $\vec{\epsilon}\sim\mathscr{N}(0,\sigma I)$. Where $sigma=bla$
%and $I$ is the $10\times 10$ identity matrix.
%In the Bayesian framework we are interest in finding the value of $b$ given the experimental measurements $m$.
%To that end we go back to the begining of this chapter and use equation (\ref{eqnpropto}). To use this equation
%we need to find the likelihood $\like(m|b)$. Under the assumption of the additive noise model in equation
%(\ref{eqnadditivenoise}) we get as in the smashed window example in chapter 2 that
%\begin{equation*}
%m|b\sim\mathscr{N}(G(b),\sigma I),
%\end{equation*}
%more precisely
%\begin{equation*}
%\like(m|b)=\frac{1}{(2\pi\sigma)^{n/2}}\exp\left(-\frac{\|G(b)-m\|_{2}^{2}}{2\sigma^{2}}\right).
%\end{equation*}
%
%
%
%Now we need to choose a prior for $b$. This is a delicate issue and a polemic one in the Statistics community.
%The prior should reflect all of our current knowledge about $b$. However your knowledge about $b$ might be 
%different than my knowledge about $b$, hence your prior for $b$ might look different than mine. For
%the moment  we won't worry about that. Let's assume that our prior for $b$ is given by
%\begin{equation*}
%b\sim U(0,2).
%\end{equation*}
%where $U(a,b)$ is the uniform distribution in $a,b$. Putting all of this into formula (\ref{eqnpropto}) we get
%\begin{equation*}
%\post(b|m)\propto\chi_{[0,2]}\exp\left(-\frac{\|G(b)-m\|_{2}^{2}}{2\sigma^{2}}\right),
%\end{equation*}
%where $\chi_{[a,b]}$ is the indicator function of the set $[a,b]$. This equation can be 
%interpreted as the update in knowledge from to prior to the posterior in the light of the
%experimental data obtained represented by the likelihood. This change from prior to 
%posterior is shown below.
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{./FigChap3/prior_posterior.jpg}
\caption{Plots for the prior distribution, posterior distribution and true value of the parameter $b$.}
\label{figlikeprior}
\end{figure} 
Having a visual representation of the posterior distribution is useful, but, in order to obtain statistics
for the possible value of $b$ we need to sample from the posterior. A family of methods that allow to sample
from fairly arbitrary distributions are known as Markov Chain Monte Carlo (MCMC). In this work we are going to 
focus in a particular algorithm known as Metropolis-Hastings  (MH). We now proceed  to explain
how MH works in practice using the posterior for $b$ in equation (\ref{eqnposteriorforb}) as an example. 
\newline
\newline
Consider the posterior distribution $\post(b|\y)$. The idea is to wander around the support of the distribution
in a way that points in the support with high probability are visited more often than those with low 
probability. For example, if we are at a point $q_{1}$ and we want to move to a point $q_{2}$ we will accept 
that move with probability one if $\post(q_{1}|\y)\leq\post(q_{2}|\y)$ and with probability 
$\frac{\post(q_{2}|\y)}{\post(q_{1}|\y)}$ otherwise. On the other hand if we are at a point $q_{1}$, we choose
in what direction to move, randomly, using some probability distribution that is easy to sample from.
In this and the next Chapter we choose the uniform distribution to decide in what  direction to move.
The pseudocode  for the MH algorithm as described above is \cite{Somersalo}

\begin{enumerate}
\item pick a point $q_{1}$ in the support of the distribution\\
\\
\textbf{for} j=2:N
\item $\qquad$Draw $u\sim U([0,\alpha])$
\item $\qquad q_{j}\leftarrow q_{j-1}+u$
\item $\qquad$Compute $\post(q_{j}|D)$
\item $\qquad\beta\leftarrow\min(1,\frac{\post(q_{j}|D)}{\post(q_{j-1}|D)})$
\item $\qquad$Draw $w\sim U([0,1])$\\
\\
$\qquad\qquad\qquad$\textbf{if} $w<\beta$ 
\item $\qquad\qquad q_{j-1}=q_{j}$\qquad(Accept move)\\
\\
$\qquad\qquad$\textbf{else}
\item
	$\qquad\qquad q_{j-1}=q_{j-1}$\\
\textbf{end}\\
\textbf{end}
\end{enumerate}

The rule of thumb for choosing the parameter $\alpha$ in the scheme above is that   the proportion of times we accept
a move 
is about $0.25$ \cite{casella2008monte}. It can be shown that the sequence $q_{1},q_{2},\ldots,q_{N}$
are realizations of a Markov chain that in the limit as $N\rightarrow\infty$ the samples come from
$\post(b|\y)$ and are independent. This convergence result works under mild conditions over the distribution that is being sampled.
For more details about the theory behind MCMC methods we refer the reader to \cite{casella2008monte}. 
Since we do not have the computational power to let $N\rightarrow\infty$
to achieve independence from the samples, what is done in practice is to consider a number $N$ as big as possible given computational and time constraints. 
Then consider only 
a fraction of the last  samples obtained. For example we may choose the last $N/2$ samples obtained from the MH scheme and 
discard the rest of the samples. The iterations where we obtain samples that we discard later is know as 
the \textit{burning period}.
\newline
Using the MH scheme to sample from the posterior distribution $\post(b|\y)$ with $\alpha=0.23$
and $N=10000$. We set the burning period to be the set  of the first $5000$ samples. Below is shown the result obtained
from sampling the posterior in equation (\ref{eqnposteriorforb}).

%Returning to the problem of sampling the posterior distribution for $b$. We are going to use the Metropolis Hastings algorithm
%using an step size of $\delta=0.23$, $10000$ samples and we chose the first $5000$ to be the burning period. The results 
%of applying the MH algorithm is shown below  
%


\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./FigChap3/histogram_mcmc.jpg}
\caption{Histogram obtained for the posterior distribution (\ref{eqnpropto}) 
from $5000$ samples from MH algorithm with step size $\alpha=0.23$. The solid line
is the  graph for the posterior $\post(b|D)$.}
\end{figure}

With the samples obtained we readily obtain useful statistics for $b$. For example we can estimate
 the conditional mean  by using Monte Carlo integration

\begin{equation}\label{eqnbcmMC}
b_{cm}=\int_{(0,2]}b\post(b|D)db\approx\frac{1}{5000}\sum_{j=1}^{5000}b_{j}=0.9247042,
\end{equation}
where the summands $b_{j}$ are the samples obtained after the burn period of $5000$ samples. We can 
also estimate the variance of this estimate as 
\begin{equation*}
\int_{(0,2]}(b-b_{cm})^{2}\post(b|D)db\approx\frac{1}{5000}\sum_{j=1}^{5000}(b_{j}-b_{cm})^{2}=0.01427.
\end{equation*}
With these values we can say that with $95\%$ of probability, the true value of $b$ belongs to the
interval
\begin{equation*}
[0.9247042-2\sqrt{0.01427},0.92470422+2\sqrt{0.01427}]=[0.68579,1.163618].
\end{equation*}


Let us digress about the idea behind Monte Carlo integration. Consider the generic problem of evaluating the $n$-dimensional
integral
\begin{equation}\label{eqnmontecarlo}
\int_{\mathbb{R}^{n}}h(x)\rho(x)dx,
\end{equation}  
where $\rho$ is the Lebesgue density of some probability measure $\p$. This means that calculating (\ref{eqnmontecarlo}) 
is equivalent to calculating the expected value of $h$, i.e.
\begin{equation*}
\mathbb{E}[h]=\int_{\mathbb{R}^{n}}h(x)\rho(x)dx.
\end{equation*}
If we have $X_{1},\ldots,X_{n}$ random variables independent with density $\rho$, then by the strong law of large numbers, the sequence of random
variables
\begin{equation*}
h_{n}=\frac{1}{n}\sum_{k=1}^{n} h(X_{k}),
\end{equation*}
converges to $\mathbb{E}[h]$\cite{dudley2002real}. Furthermore if $\mathbb{E}[h^{2}]<\infty$ we can assess the speed of
convergence and the quality of the approximation $h_{n}$ for $\mathbb{E}[h]$. By the central limit theorem
the sequence of random  variables $h_{n}$
\begin{equation*}
\frac{h_{n}-\mathbb{E}[h]}{\sqrt{\sigma_{n}}}\rightarrow \mathcal{N}(0,1),
\end{equation*}
where 
\begin{equation*}
\sigma_{n}=\frac{1}{n}\sum_{k=1}^{n}(h(X_{k})-h_{n})^{2}.
\end{equation*}
This means that the uncertainty in the approximation $h_{n}$ for $\mathbb{E}[h]$ goes to $0$ as $\mathcal{O}(\frac{1}{\sqrt{n}})$.
In practice, to estimate the quality of the result from the Monte Carlo integration we use the approximation
\begin{equation*}
\p\left(\frac{h_{n}-\mathbb{E}[h]}{\sqrt{\sigma_{n}}}\leq x\right)\approx\Phi(x),
\end{equation*}
where 
\begin{equation*}
\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}\exp(-\frac{x^{2}}{2})dx.
\end{equation*}
\newline

To conclude this Chapter we are going to turn our attention into the subjective part of Bayesian statistics.  We are 
going to talk about  the role the  prior probability has in the inference process. 




\subsection*{How important is the prior to make inferences?}
It is constructive to  explore how relevant is the choice  of the prior distribution
in making inferences about a parameter of interest. Let us consider the same problem,
we want to estimate
the value of the parameter $b$. For demonstration purposes, let us assume two things: the parameter
$b$ can be any real number (not just $0<b\leq 2$ as before) and we assume a prior distribution for $b$ as
\begin{equation*}
b\sim\mathscr{N}(b^{*},\sigma_{b}^{2}),
\end{equation*}
where $b^{*}$ and $\sigma_{b}$ are parameters to be set later.  With this new prior the formula
for the posterior is calculated as 
\begin{equation*}
\post(b|\textbf{y})\propto\underbrace{\exp\left(-\frac{\|\textbf{y}-\textbf{G}(b)\|_{2}^{2}}{2\sigma^{2}}\right)}_{\text{Likelihood}}\underbrace{\exp\left(-\frac{(b-b^{*})^{2}}{2\sigma_{b}^{2}}\right)}_{\text{Prior}}.
\end{equation*}
As before, assume that the true
value of $b$ is $0.925$. To illustrate the role that the prior has in the inference of the value
of the parameter given the data $\textbf{y}$, suppose that 
\begin{equation*}
b\sim\mathscr{N}(4,2.5).
\end{equation*}
This prior assumes that, with $95\%$ of confidence, the value of
$b$ is in the interval $[1.8,8.2]$. Clearly there is a mismatch between
the true value of $b$ and the range of values that the prior distribution
assign with high probability. Let us evaluate how the posterior
distribution for $b$ evolves as we consider more and more experimental
data from the measurements of $\tilde{u}$.  In Figure \ref{figpostevolution} it is shown
how the posterior evolves when we calculate the likelihood with more 
and more data. The first frame shows the result when only the measurement
$\tilde{u}(\x_{1};b)$ is taken into account. The second frame
when the measurements $\tilde{u}(\x_{1};b),\tilde{u}(\x_{2};b)$ are taken
into account. In each frame we proceed adding one more measurement 
at a time and in the tenth frame we calculate the posterior
using the data obtained from all ten points.

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{./FigChap3/posterior_evolution}
\caption{Evolution of the posterior distribution when more experimental data is taken into account}
\label{figpostevolution}
\end{figure}

The sequence of plots in Figure \ref{figpostevolution} shows that the experimental data creates a new mode
in the posterior distribution that is close to the true value of $b$. In the end of the sequence where we consider
all 10 experimental measurements, the mode that is close to the true value of $b$ is bigger than the mode originate
by the prior at the point $b=4$. The reason for this final posterior distribution is that the prior gives a large
probability to values around $b=4$, whereas give a close to zero probability for values around $b=0.925$.
When the experimental data is used, the likelihood distribution points to values close to $b=0.925$. The more data
we use the stronger the weight that the likelihood has compared to the prior distribution. However since
the prior distribution gives negligible probability to the true value of $b$, when all data are used there
is an equilibrium between the likelihood and prior that is expressed as a bimodal distribution. This result
is a cautionary tale. If we know how to choose the prior distribution in a way that is meaningful to the
problem, reliable inference could be done with small amount of data. On the contrary if the prior distribution
is not realistic, inference may not be reliable and a big amount of data is needed
to correct for the bias included in the prior distribution. We can summarize this with the following analogy: if you really believe
in Santa you will need significant  evidence that he does not exist to stop believing in his existence.

\chapter{Industrial Case Problem}

Some introduction: relate the need to find the forward map in order to solve the problem
of finding the parameters. 

\section{A Mathematical Model for Pollutant Dispersion}
Our starting point is the conservation of mass. In particular conservation of mass for
particulated zinc in the atmosphere. Consider a volume of space $V$ with a mass
amount $m$ of zinc in it. Assume
that within $V$ there is  a source of  zinc. Further assume that zinc is flowing inside the volume 
and leaving the volume at the same time due to the presence of wind (see Figure bla).
If $\textbf{v}$ represents the wind velocity it can be shown that net amount
per unit time of zinc that is flowing through the surface is given by the expression
\cite{seinfeld1998atmospheric}
\begin{equation*}
\oint_{\partial V}c(\x,t)\textbf{v}\cdot\textbf{n}dA,
\end{equation*}
where $\partial V$ is the boundary of $V$ and $c(\x,t)$ is the concentration of zinc at a point $\x$
at time $t$.
The units of $c$ are given in units of mass per units of volume. On the other hand
the rate of change total mass at a time $t$ inside $V$  can be calculated as
\begin{equation*}
\frac{dm(t)}{dt}=\frac{d}{dt}\int_{V}c(\x,t)dV.
\end{equation*}
Finally if the amount of zinc that comes from the source at a time $t$ is given by
\begin{equation*}
\int_{V}s(\x,t)dV,
\end{equation*}
where $s(\x,t)$ is the source density. Its units are mass per unit volume per unit time.
Conservation of mass states that the total mass inside $V$ should be conserved. Therefore
for all time the rate of change of the mass inside $m$ should equal all source of variation of it.
Mathematically we can write
\begin{equation*}
\frac{d}{dt}\int_{V}c(\x,t)dV=-\oint_{\partial V}c(\x,t)\textbf{v}\cdot\textbf{n}dA+\int_{V}s(\x,t)dV.
\end{equation*}
Since we picked the orientation of $\partial V$ with the normal pointing outwards, it is
necessary to put a minus in front of the surface integral for consistency. Assuming
the concentration and the velocity field are continuous functions of time and space, an 
straight forward application of the divergence theorem and Leibniz rule for integral gives
\begin{equation}\label{eqnDeterministic}
\frac{\partial c(\x,t)}{\partial t}+\nabla\cdot(c\textbf{v})=s(\x,t).
\end{equation}
If we apply this equation to estimate the concentration of zinc using real wind data, we 
will find that the prediction is not completely accurate. The reason is that at small scales, there
are random fluctuations in the wind velocity. To model this we follow \cite{seinfeld1998atmospheric}
and write the wind velocity as
\begin{equation}\label{eqnNewV}
\vv=\bar{\vv}+\vv',
\end{equation}
where $\bar{\vv}$ is the measured wind velocity and $\vv'$ is a random variable with zero mean.
If we replace $\vv$ in equation (\ref{eqnDeterministic}) with the expression for velocity
in equation (\ref{eqnNewV}) we get
\begin{equation}\label{eqnNewRandom}
\frac{\partial c(\x,t)}{\partial t}+\nabla\cdot(c(\bar{\textbf{v}}+\vv'))=s(\x,t).
\end{equation}
The presence of the random variable $\vv'$ transforms the solution $c$ into a random 
variable as well. In this case we describe $c$ as the contribution of two terms
\begin{equation*}
c=\E(c)+c',
\end{equation*}
where $c'$ satisfies $\E(c')=0$. The intuition behind this definition is that if we experimentally
measure the concentration repeating the same experiment a high number of times. We expect the 
concentration to have an underlying average behavior $\E(c)$ plus some  noise represented by $c'$.
Plugging in this new representation of $c$ into equation (\ref{eqnNewRandom}) we obtain
\begin{equation}\label{eqnInconsistent}
\frac{\partial\E(c)}{\partial t}+\dv(\bar{\vv}\E(c))+\dv(\E(c'\vv'))=s(\x,t).
\end{equation}
The problem with this new equation is that we have the extra variable $\E(c'\vv')$.
This means we have  more unknowns than equations. 
One way to overcome this issue is given by the so-called mixing-length theory. The
theory uses the constitutive equation
\begin{equation*}
\E(c'\vv')=D\nabla(\E(c)),
\end{equation*}
the term D is  a rank two tensor called the eddy diffusivity tensor. This tensor is assumed 
to be symmetric, hence is always diagonalizable. We may assume that we are working
in the principal axis of $D$. Note that  In general we do not have enough information to believe the tensor
to be non-diagonal \cite{seinfeld1998atmospheric}, hence 

\begin{equation*}
D=\begin{bmatrix}
D_{xx}& 0 & 0\\
0 & D_{yy} & 0\\
0 & 0 & D_{zz}
\end{bmatrix}.
\end{equation*}
Under the mixing-length theory the equation (\ref{eqnInconsistent}) reads as
\begin{equation*}
\frac{\partial\E(c)}{\partial t}+\dv(\bar{\vv}\E(c)+D\nabla\E(c))=s(\x,t).
\end{equation*}
The variable $\E(c)$ is a deterministic function of space and time. So to make
notation lighter we set $C(\x,t):=\E(c)$. Hence our forward equations
reads as
\begin{equation*}
\frac{\partial C(\x,t)}{\partial t}+\dv(\bar{\vv}C(\x,t)+D\nabla C(\x,t))=s(\x,t).
\end{equation*}
\textbf{To do know is to tell how to deal with the fact that we don't know the velocity
closed form nor the fucking components of D, use Bamdad's paper for that}
\bibliography{Tesis}
\bibliographystyle{plain}
\end{document}
