%%%%%%%%%%%%%%%%%%%%Tesis File%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{book}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[pdftex]{graphicx}
\usepackage{setspace}
\usepackage{mathrsfs}
\usepackage{float}
\usepackage{pbox}
%\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{algorithm}
\usepackage{algpseudocode}



\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
%\usepackage{fancyhdr,floatpag}

%\pagestyle{fancy}
%\fancyhf{}% Clear page header/footer
%\renewcommand{\headrulewidth}{0pt}% No header rule
\fancyfoot[C]{\thepage}

%\floatpagestyle{fancy}% Page style for float-page only
%Theorems
\newtheorem{definition}{Definition}




%Commands

%Prior, posterior and likelihood
\newcommand{\post}{\mathbb{P}_{post}}
\newcommand{\like}{\mathbb{P}_{like}}
\newcommand{\prior}{\mathbb{P}_{prior}}
\newcommand{\p}{\mathbb{P}}
\newcommand{\q}{\textbf{q}}
\newcommand{\pars}{p,z_{0},L}
%Other commands
\newcommand{\E}{\mathbb{E}} %Expectation
\newcommand{\tvs}{\mathscr{T}} %TVS symbol
\newcommand{\x}{\textbf{x}}
\newcommand{\y}{\textbf{y}}
\newcommand{\vv}{\textbf{v}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\dv}{\nabla\cdot}



\begin{document}
\setlength{\unitlength}{1 cm} %Especificar unidad de trabajo
\thispagestyle{empty}
\begin{center}
    %\begin{picture}(18,4)
    %\centering
    \includegraphics[scale=0.5]{log.png} \\[1cm]
    %\end{picture}
\textbf{{\LARGE Simon Fraser University}\\[0.5cm]
{\LARGE Faculty of Sciences, Math Department}}\\[1.25cm]
\begin{doublespace}
{\huge \textbf{Here comes the title}}\\[1.5cm]
\end{doublespace}
{\large Juan Gabriel Garc{\'i}a Osorio}\\[1cm]
Advisor: John Stockie\\[1cm]
Commitee: Paul Tupper\\[1cm]
Burnaby B.C - May  2017
\end{center}

\newpage
\tableofcontents


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Acknowlegments}
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 1: Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 2: Theoretical and Computational Framework %%%%%%%%%%%%%%%%
\chapter{Theoretical and Computational Framework}
%\pdfmarkupcomment[markup=Squiggly,color=green]{what eve}{Change this shit}


The framework of Bayesian statistics is the foundation of  our approach to estimate parameters and solve 
inverse problems. Unlike frequentist statistics, in the Bayesian approach, randomness
is a measure of uncertainty,  not a matter of frequency. Consider an statement such  as:
the probability of having life in the universe is 0.01. In the frequentist
perspective, this number is interpreted as: for every hundred planets, on average, one planet shelters life.
 In the Bayesian
perspective the number 0.01 is interpreted as a measure of how certain we are about life in the universe
given the current state of knowledge about the outer space. 
Clearly there is a big philosophical
difference between these two approaches that has a direct impact in how far reaching is each point of view  \cite{jaynes2003probability}.


%Talking about Bayes rule
At this point we mention that when we talk about uncertainty we are talking about every possible 
source of randomness  or  lack of information. That is, the use of the word uncertainty in this work
is related to either epistemic (A phenomenon might not be random but the complete lack of 
understanding of it makes us see it as random) or aleatory (Inherent to the nature of phenomenon, for 
example this is the kind of randomness physicists believe is happening in quantum mechanics)
\cite{kennedy2001bayesian}. In real life the uncertainty associated with a  measurement or  quantity 
of interest is usually connected  with the uncertainty  of other variables involved in the problem under study. 
The Bayesian framework provides a rigorous framework to study these uncertainties, 
using whatever information is available for the problem. The cornerstone of this framework
in the mathematical language is known as   Bayes' formula given by

\begin{equation}\label{eqnBayes}
\post(A|B)=\frac{1}{Z}\like(B|A)\prior(A).
\end{equation}
Intuitively, Bayes' rule says that the probability of the event $A$ to happen given that $B$ was observed is
proportional to the probability of $B$ to happen given $A$ was observed. This value is weighted by 
the probability of $A$ to happen. Finally, $Z$ is a normalization constant.

Let us make sense of  equation \ref{eqnBayes} in a more rigorous setting. 
We begin with the following definitions taken from
\cite{dudley2002real}.
\begin{definition}\label{dfnprobabilitytriple}
A probability space is a triple $(\Omega,\mathscr{F},\p)$, where $\Omega$ is a set called 
sample space, $\mathscr{F}$ is a collection of subsets of $\Omega$ that satisfies
\begin{enumerate}
\item $\emptyset,\Omega\in\mathscr{F}$.
\item If $A\in\mathscr{F}$ then $A^{c}\in\mathscr{F}$.
\item If $A_{1},A_{2},\ldots \in\mathscr{F}$ then $\bigcup_{i\in\mathbb{N}}A_{i}\in\mathscr{F}$.
\end{enumerate}
A  collection of sets that satisfies properties 1 to 3 is called a $\sigma-$ algebra and its elements are called
events. 
\\
The map $\p:\mathscr{F}\rightarrow [0,1]$ is called a probability measure and satisfies
\begin{enumerate}
\item $\p(\Omega)=1$.
\item If $A_{1},A_{2},\ldots \in\mathscr{F}$ are pairwise disjoint, then 
\begin{equation*}
\p(\bigcup_{i\in\mathbb{N}}A_{i})=\sum_{i\in\mathbb{N}}\p(A_{i}).
\end{equation*}
\end{enumerate}
\end{definition}

\begin{definition}
Given a probability space $(\Omega,\mathscr{F},\p)$ and two events $A,B\in\mathscr{F}$, with $\p(B)\neq 0$. 
We define the conditional probability of $A$ given $B$ by

\begin{equation*}
\p(A|B)=\frac{\p(A\cap B)}{\p(B)}.
\end{equation*}
\end{definition}



%In equation (\ref{eqnBayes}), $\p,\prior,\like,\post$ are different probability measures defined in the
%same sample space $\Omega$. 
Going back to equation (\ref{eqnBayes}), the sets $A$ and $B$ are subsets of the sample space $\Omega$ and 
are elements of the associated $\sigma-$algebra $\mathscr{F}$. The  notation
 $\like(\cdot|\cdot)$ or $\post(\cdot|\cdot)$, denotes conditional probability. Let us introduce some terminology:
 the term $\like(B|A)$ is called the \textit{likelihood} of $B$ given $A$. The term $\prior(A)$ is called the 
\textit{prior} probability for $A$. The prior probability expresses how much we believe the event $A$ 
to happen without assuming
anything about  $B$. The reciprocal of $Z$ is a \textit{normalization constant} defined as 

\begin{equation}\label{eqnNormalizationConstant}
Z=\int_{\Omega} \like(B|A)d\prior.
\end{equation}

The term $\post(A|B)$ is  the \textit{posterior} probability of $A$ given $B$. The integral
is understood in the  Lebesgue sense as the  integral with respect to the measure $\prior$ \cite{lerner2014course}. 
The posterior contains  the information 
that we gained by comparing our beliefs (decoded in the prior probability) with experimental data 
(decoded in the likelihood). 
\newline



%Ilustratory example
Now we look at the connection between Bayesian statistics and  the field of inverse problems. 
Inverse problems are  often concerned with finding the cause of an effect. Whereas a forward
problem is concerned with finding the effect of a cause. If we have information about the 
forward problem, then we can use it to get information about the inverse problem. Bayes rule
puts in a mathematical language the connection between inverse and forward problem. 
If we consider the cause to be the
event $A$ and the effect the event $B$, then the information of the forward problem
is encoded in $\like(B|A)$. The information of the inverse problem is contained in 
$\post(A|B)$. That is why in the Bayesian framework, the posterior probability
is the $\textit{solution to an inverse problem}$.

Often, inverse problems
are ill-posed, this means
that these problems might  not satisfy one or more of the following properties \cite{lebedev2012functional}:

\begin{itemize}
\item Existence: There exists a solution for the problem.
\item Uniqueness: The problem has a unique solution.
\item Stability: Small changes in inputs result in small changes in outputs.
\end{itemize}
This is a serious issue. For example, if the problem under study has at least one solution
but is unstable to small perturbations, how can we assess the accuracy of the solution to 
the problem. 
Therefore an statistical or non-deterministic approach is called for . As explained before, the Bayesian framework 
is useful in this context. Bayes'rule connects the inverse problem  of finding the cause
of an effect through the posterior with the forward problem of finding the effect of a cause
through the likelihood in a way that is possible to quantify the uncertainty about the solution
of the problem. Let us  clarify with an example of how the Bayesian framework can be used to solve inverse problems. 
\newline

Consider the problem of finding the launch location of a rock that impacted (and cracked) a window. 
We can start by considering the following events
\begin{align*}
& A=\text{Coordinates of the launching location}.\\
& B= \text{Coordinates of the  location impact in the window}.
\end{align*}
Here we assume we know $B$, but $A$ is unknown. We can use Bayes' rule to estimate $A$ through
the posterior $\post(A|B)$. In this case
we need to find the connection with the forward problem, i.e. given 
the launch coordinates find the location impact. This connection is encoded in the likelihood $\like(B|A)$.
In addition we also need to set the prior probability for $A$. 
\newline



Let us explain how we could estimate the different probabilities mentioned in the previous paragraph. 
First, to find the likelihood
we need to know how the rock's impact position  in the window  is related to the launch location. 
If we treat air resistance as a source of uncertainty  we can use
the kinematics equations  for parabolic trajectories to get \cite{arnol2013mathematical}
\begin{equation}\label{eqnKinematics}
\textbf{r}=\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2},
\end{equation} 
where $\textbf{r}$ and $\textbf{r}_{0}$ are the final and initial position of the rock, 
$\textbf{v}_{0}$ is 
the initial velocity of it,  and $\textbf{g}$ is  a vector that points to the center of the earth and has a 
magnitude equal to the value of the acceleration of gravity. The scalar $t$ represents time.
In a more physical language, to compute the likelihood it is necessary to estimate $\textbf{r}$ (where the 
rock hit the window) assuming we know $\textbf{r}_{0}$ (where it was thrown), and the initial velocity 
of the rock $\textbf{v}_{0}$. 
Once all the other variables are identified the value of $t$ can be computed in a straightforward manner. 

Equations in physics are just models of reality and as such are just an approximation to it. To take
this into account we add an extra layer to the model by adding a random parameter that accounts
for the discrepancy of our model with reality. We propose 
\begin{equation}\label{eqnParabolicEpsilon}
\textbf{r}=\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2}+\mathbf{\epsilon},
\end{equation} 
where $\mathbf{\epsilon}$ is a \textit{random vector} distributed as \textit{multivariate Gaussian}. 
Before we proceed it is necessary to define more terminology and mathematical objects  that are going 
to be used throughout the rest of the text. 

\begin{definition}
Given a set $\Omega$, for any subset $T\subset\Omega$, we define the $\sigma-$algebra generated by $T$ as
the smallest $\sigma-$algebra in $\Omega$ that contains $T$.
\end{definition}

\begin{definition}
Let $O$ be the set of all open sets in $\mathbb{R}^{n}$. The $\sigma-$algebra generated by $O$ is called
the Borel $\sigma-$algebra and is denoted by $\mathcal{B}^{n}$. If $n=1$ we set 
$\mathcal{B}^{1}:=\mathcal{B}$.
\end{definition}

\begin{definition}
Given a probability space $(\Omega,\mathscr{F},\p)$, a function $X:\Omega\rightarrow\mathbb{R}$ is called 
a random variable
if $X^{-1}(C)\in\mathscr{F}$ for all $C\in\mathcal{B}$.
\end{definition}

\begin{definition}
 An $n$-dimensional random vector $\textbf{X}=(X_{1},\ldots,X_{n})$ in $(\Omega,\mathscr{F},\p)$ 
is a function $\textbf{X}:\Omega\rightarrow\mathbb{R}^{n}$, such that each component is a random variable. 
Note that a random variable can be considered as a one dimensional random vector.
\end{definition}

\begin{definition}
Given a probability space $(\Omega,\mathscr{F},\p)$ and an $n$-dimensional  random vector 
$\mathbf{X}:\Omega\rightarrow\mathbb{R}^{n}$.
Its distribution  is the probability measure
\begin{equation*}
\mu:\mathcal{B}^{n}\rightarrow [0,1],
\end{equation*}
where  $\mu$ defined by 
\begin{equation*}
\mu:=\p\circ \textbf{X}^{-1}.
\end{equation*}
\end{definition}
\begin{definition}
Given a random vector $\textbf{X}:\Omega\rightarrow\mathbb{R}^{n}$ with
probability distribution $\mu$. We say that $\mathbf{X}$ is absolutely 
continuous with respect to the Lebesgue measure if there exists a real valued, integrable function $\rho$
such that for all $C\in\mathcal{B}^{n}$ we have
\begin{equation*}
\mu(C)=\int_{C}\rho(x)dx.
\end{equation*}
We say that $\rho$ is the density function for $\mathbf{X}$.
\end{definition}
\begin{definition}\label{dfnrandonvariables}
Given an $n$ dimensional random vector $\mathbf{X}$ such that for any 
$C\in\mathcal{B}^{n}$ we have
\begin{equation}\label{eqnmultivariateGaussianDefinition}
\mu(C)=\int_{C}
\frac{1}{2\pi det(\Sigma)^{-\frac{1}{2}}}\exp((\textbf{x}-\textbf{x}^{*})^{T}\Sigma^{-1}
(\textbf{x}-\textbf{x}^{*}))d\textbf{x},
\end{equation}
then we say
that $\textbf{X}$ has multivariate Gaussian distribution or just Gaussian, 
with mean $\textbf{x}^{*}\in\mathbb{R}^{n}$
and covariance matrix $\Sigma$. The matrix $\Sigma$ is symmetric and positive definite. We shall write
\begin{equation}\label{eqnMultivariate}
\textbf{X}\sim \mathcal{N}(\textbf{x}^{*},\Sigma).
\end{equation}
In this case the components of $\textbf{X}$ are said to be \textit{jointly Gaussian}.
\end{definition}

We now return to equation (\ref{eqnParabolicEpsilon}). We assume $\epsilon\sim\mathcal{N}(0,\sigma^{2}I)$.
Here $I$
represents the $3\times 3$ identity matrix and $\sigma>0$ parametrizes One belief in quantifying the 
accuracy  
of equation (\ref{eqnKinematics}).  By introducing a random variable into the model
we make all variables involved  in equation (\ref{eqnKinematics})
to be  random variables, that is, we now look at the  associated stochastic equation. With this notation
we can cast equation (\ref{eqnBayes}) into  (assuming independence between $\textbf{r}_{0}$ and $\textbf{v}_{0}$)
\begin{equation}\label{eqnpostrock}
\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})=\frac{\like(\textbf{r}|\textbf{r}_{0},\textbf{v}_{0})
\prior(\textbf{r}_{0})}{Z}.
\end{equation}



Since $\mathbf{\epsilon}$ is Gaussian we can readily obtain \cite{Somersalo}
\begin{equation*}
\textbf{r}|\textbf{r}_{0},\textbf{v}_{0}\sim \mathscr{N}(\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2}
,\sigma^{2} I).
\end{equation*}
This last equation gives an explicit density for the likelihood. 

We now turn our attention to  the prior.
Suppose that we suspect that the rock was thrown from the bedroom of one of our neighbors.
 One way to model this suspicion is to assume a prior distribution on $\textbf{r}_{0}$ as
\begin{equation*}
\textbf{r}_{0}\sim\mathscr{N}(\textbf{w},\lambda^{2} I),
\end{equation*}
where $\textbf{w}$ is the coordinate vector of the center of mass of our neighbor's room and $\lambda$ represents 
One belief the launch location is at the point $\textbf{w}$. We note that  this is one way to model 
 prior knowledge and other priors are also possible for our problem. Finally the normalization constant $Z$
is given by the expression in equation (\ref{eqnNormalizationConstant}). Explictly we have
%probabilities  are normalized, if we integrate over the whole space equation (\ref{eqnpostrock}), we get
%\begin{eqnarray*}
%1=\int_{\mathbb{R}^{3}}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})d\textbf{r}_{0}\\
%=\int_{\mathbb{R}^{3}}\frac{\like(\textbf{r}|\textbf{r}_{0},\textbf{v}_{0})
%\prior(\textbf{r}_{0})}{\p(\textbf{r}|\textbf{v}_{0})}d\textbf{r}_{0}.
%\end{eqnarray*} 
%Since the denominator in the last integrand is  constant with respect to the variable of integration 
%we conclude
\begin{align*}
Z&=\int_{\mathbb{R}^{3}}\like(\textbf{r}|\textbf{r}_{0},\textbf{v}_{0})
\prior(\textbf{r}_{0})d\textbf{r}_{0}\\
&= \frac{1}{(2\pi)^{6}(\sigma\lambda)^{3}}\int_{\mathbb{R}^{3}}
\exp(-\frac{1}{2\sigma^{2}\lambda^{2}}
\left(\|\textbf{r}-(\textbf{r}_{0}+\textbf{v}_{0}t+\frac{1}{2}\textbf{g}t^{2})\|^{2}
+\|\textbf{r}_{0}-\textbf{w}\|^{2}\right)d\textbf{r}_{0}.
\end{align*}


Having the likelihood, prior and normalization constant allow us to compute the posterior using
Bayes rule. With these probabilities calculated 
we can obtain different kind of estimates for the value $\textbf{r}_{0}$.  
Common choices of pointwise estimates include

%
%
%For the moment assume we have the means to sample from the 
%posterior in equation (\ref{eqnpostrock}). By having samples from the posterior we can obtain
%pointwise estimates of the parameters of interest. Common choices of pointwise estimates
%include
\begin{eqnarray}\label{eqnpointestimates}
\textbf{r}_{MAP}=argmax_{\textbf{r}_{0}}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0}) 
\qquad\text{(Maximum a posteriori),}\\
\textbf{r}_{CM}=\int_{\mathbb{R}^{3}}\textbf{r}_{0}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})d\textbf{r}_{0}.
\qquad\text{(Conditional mean)}, \\
\textbf{r}_{ML}=argmax_{\textbf{r}_{0}}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0}).
\qquad\text{(Maximum likelihood).}
\end{eqnarray}

Each  of these estimates have strengths and weaknesses. If the posterior is bimodal, then the conditional
mean might point at a value with very low probability, whereas the maximum a posteriori might be more 
reliable. If the posterior has no critical points then the mean might be use as a point estimate. We can 
also assess how confident we are about the point estimate. For example, if $\textbf{r}^{*}$ is our point
estimate we can calculate a number $\alpha>0$ such that

\begin{equation*}
\int_{B(\textbf{r}^{*},\alpha)}\post(\textbf{r}_{0}|\textbf{r},\textbf{v}_{0})d\textbf{r}_{0}=0.95,
\end{equation*}

where $B(\textbf{r}^{*},\alpha)$ is the ball centered at $\textbf{r}^{*}$ and radius $\alpha$. This 
value of $\alpha$ can be thought of as  the Bayesian version 
of the frequentist's $95\%$ confidence interval.
Another way to estimate the uncertainty is by calculating the covariance matrix of $\textbf{r}$
around $\textbf{r}_{0}$ as
\begin{equation*}
\int_{\mathbb{R}^{3}}(\textbf{r}_{0}-\textbf{r}^{*})\otimes(\textbf{r}_{0}-\textbf{r}^{*})d\post.
\end{equation*}
\newline
The diagonal of this matrix will  contain the variance of each of the coordinates of $\textbf{r}^{*}$.

Note that the posterior is a probability density and it does not necessarily have a closed form. This
makes difficult to calculate the uncertainties we mentioned above.
Hence we need a way of extracting information from the posterior. One approach is to generate 
independent samples
from it and do a Monte Carlo integration   to obtain the different uncertainty estimates. 
How to sample from a probability 
density and do a Monte Carlo integration are going to be explained in Chapter 3. For the moment
assume it is possible to evaluate any of the point estimates and the uncertainty measures. With 
this we obtained a way to estimate the launch location of the rock and how confident we are
about that estimate. 
\newline


%Caveats of computing complex models
Practical problems are often substantially more challenging than in the above example. Often times we have to 
deal with several issues such as 

\begin{enumerate}
\item Uncertainties in experimental measurements.
\item Lack of sufficient information and data.
\item Computational complexity of  physical models that are too expensive to evaluate.
\item Parameters that might belong to high dimensional spaces so the associated probability density is 
hard to sample from.
\item Evaluating any of the possible point estimates for the quantity of interest might be very hard.
\end{enumerate}
In the problem that we outlined in  Chapter 1, we have to deal with all of  the above mentioned issues.
In this chapter we are going to discuss our approach to deal with issues 3, 4 and 5 above. We 
omit 1 and 2, since these  are intrinsic to the physics of the problem and   the methodology used 
to obtain the experimental data, and so, are out of our hands.


%%%%Dealing with computational complexity
\section{Dealing with  the computational complexity of the physical model}
Models of physical processes are often complex and   expensive to simulate numerically, therefore we need
a way of reducing this complexity.
Following O'Hagan  \cite{o2006bayesian}, we think of our  mathematical model of the physical process
 as a function
$M(\cdot)$ so that $y=M(\x)$ where $\x\in\mathbb{R}^{n}$   and $y\in\mathbb{R}$.
Mathematical models are approximations to physical processes and as such there are discrepancies between
models and reality. It is then necessary to address the validity  of the model. One way to do
this is by performing a sensitivity analysis on the parameters the model depend on. Roughly, we choose a
combination of different values of the parameters and then we assess the importance of each one in
the output of the model. This means that we need to run the model $M(\cdot)$ for a large set 
of different combination of its parameters.
Since mathematical models are expensive,
this implies that   the  use of   classical methods such  as correlation
ratios, FAST method, Method of Sobol', etc. 
 are not feasible (see \cite{saltelli2000sensitivity} for details). 

Here the concept of emulator as defined in \cite{o2006bayesian} 
comes into play. We 
approximate the function $M(\cdot)$, which is  expensive to evaluate,
 with a function $\widehat{M}(\cdot)$ that is cheap to evaluate. To construct such an approximation,   
we  associate a 
probability distribution to each  possible value of $M(\textbf{x})$ and for example take 
$\widehat{M}(\x)$ to be  the mean
of this distribution. We will refer to $\widehat{M}(\cdot)$ as an emulator. 
Following \cite{o2006bayesian} we expect the emulator to satisfy the conditions in 
the following definition
\begin{definition}\label{dfnEmulator}
An emulator $\widehat{M}(\cdot)$ of a function $M(\cdot)$, is a map that:
\begin{itemize}
\item At points $\{\x\}_{k=1}^{N}$  were we know the output of the mathematical model i.e. we know 
$M(\x_{k})$ for $k=1,2,\ldots, N$,
the emulator should satisfy $\widehat{M}(\x_{k})=M(\x_{k})$.
\item For  points $\{\x_{k}^{*}\}_{k=1}^{T}$ where we don't know the output $M(\x_{k}^{*})$, the emulator should
give back an estimate $\widehat{M}(\textbf{x}_{k}^{*})$, based on the distribution for $M(\textbf{x}_{k}^{*})$. 
That estimate should reflect the uncertainty associated with
the interpolation/extrapolation done at that point.
\end{itemize} 
\end{definition}


From now on in this work we are going to refer to the mathematical model or the computationally expensive
function to calculate as $M(\cdot)$. The emulator that approximates this function is going to be denoted by 
$\widehat{M}(\cdot)$.
%Talking about Gaussian processes

A very popular  method to construct an emulator with the desired
extrapolation/interpolation properties is what is known as a Gaussian process regression.  

\subsection{Gaussian Processes}
The conditions on the emulator $\widehat{M}(\cdot)$, imply that we need
to work with a probability distribution for each point $\textbf{x}$ in the domain of the model $M(\cdot)$.
This means that  we need to work with 
 a set of random variables  with high cardinality. 
When dealing with 
several random variables there is one probability density that is computationally tractable and
easy to work with: the multivariate Gaussian distribution (see Definition \ref{dfnrandonvariables}). 
The computational tractability  of the multivariate Gaussian distribution, can be used as a justification
to define what a Gaussian process is.
\begin{definition}\label{dfnGP}
A Gaussian process (GP) is a collection of random variables $\{g(x)\}_{x\in A}$, for some set $A$, 
possibly uncountable,
 such that any finite subset of random variables
 $\{g(x_{k})\}_{k=1}^{N}\subset\{g(x)\}_{x\in A}$ for 
$\{x_{k}\}_{k=1}^{N}\subset A$ are jointly Gaussian
\cite{rasmussen2006gaussian}. 
\end{definition}

A GP is specified by a mean function and a covariance operator or covariance kernel. 
Following  Rasmussen \cite{rasmussen2006gaussian} we define
\begin{align*}
& m(x):=\E(g(x)),&&\qquad\text{(Mean)}\\
& k(x,x'):=\E((g(x)-m(x))(g(x')-m(x')))&&\qquad\text{(Kernel)}.
\end{align*}
If $\{g(x)\}_{x\in A}$ is a GP with mean $m(x)$ and covariance $k(x,x')$ we will write
\begin{equation*}
g(x)\sim \textbf{GP}(m(x),k(x,x')).
\end{equation*} 

To  understand why the notion of a GP is useful for us, recall that our goal is to create
an emulator $\widehat{M}(\cdot)$ that approximates a function $M(\cdot)$. 
For a fixed $\x\in A$, a realization of the  random variable $g(\x)$ represents
a possible value of $M(\x)$. The mean function at that point $\x$, i.e. $m(\x)$ 
represents the best prediction about the true value of $M(\x)$. We may set
$\widehat{M}(\x)=m(\x)$. Later we will show that one way to measure the  uncertainty 
associated with that prediction is given by the quantity $k(\x,\x)$.

 

We are going to use GPs to fit  functions in  high dimensional euclidean spaces, so from 
now on we may think
of the  index set $A$ of Definition \ref{dfnGP} as a subset of $\mathbb{R}^{n}$ for some $n\geq 1$. 
\newline

The reason why  Gaussian processes are useful in practice is that  they are 
completely characterized by the mean $m(x)$ and the covariance kernel $k(x,x')$\cite{lifshits2012lectures}. 
 For example a  common covariance or kernel is the
 squared exponential (SE) function given by  
\begin{equation}\label{eqnsquareexponential}
k(x,x')=e^{-\frac{1}{2}\|x-x'\|_{2}^{2}}.
\end{equation}
We choose to use the name squared exponential instead of 
Gaussian to avoid confusion with
the probability distribution.
This  covariance function tells us that if $\x,\x'$ are close in the Euclidean metric 
then they are highly correlated whereas far away points have a correlation that decays exponentially fast.
How to choose the covariance function depends on the kind
of regularity we want for the realizations of the GP. We will discuss this topic in
more detail later in the chapter. For the moment for reference purposes, we show 
some of the most common kernels used in practice \cite{rasmussen2006gaussian} (setting $r=\|x-x'\|_{2}$)

\begin{itemize}
\item Squared-Exponential: $k(r;\theta)=e^{-\frac{1}{2}(\frac{r}{\theta})^{2}}$
\item Exponential: $k(r;\theta)=e^{-\frac{r}{\theta}}$\\
\item Matern $\frac{3}{2}: k(r;\theta)=(1+\frac{\sqrt{3}r}{\theta})e^{-\frac{\sqrt{3}r}{\theta}}$.
\item Matern $\frac{5}{2}: k(r;\theta)=(1+\frac{\sqrt{5}r}{\theta}+\frac{5}{3}
(\frac{r}{\theta})^{2})e^{-\frac{\sqrt{5}r}{\theta}}$.
\item Power-Exponential: $k(r;\theta,p)=e^{-(\frac{r}{\theta})^{p}}$.
\end{itemize}





\subsubsection{Gaussian Processes as Distributions Over Function Spaces}

Alternatively GPs can be viewed as  measures on function spaces. We now discuss them in this
context following the approach of \cite{lifshits2012lectures}.
\newline
Interesting function spaces (e.g. $L^{p}$ spaces, Sobolev spaces, etc...) are 
normed vector spaces, with a topology inherited from the metric induced by the norm, and so 
, interesting function spaces are topological vector spaces (TVS). 

Let $\mathscr{T}$ be a TVS and  let $\mathscr{T}^{*}$ be its topological dual. 
We will denote the action of an 
element $h\in\tvs^{*}$ over an element $z\in\tvs$ with $\langle h,z\rangle$. Moreover 
we  define a random variable taking values in $\tvs$ as a map 
\begin{equation*}
X:(\Omega,\mathscr{F},P)\longrightarrow\tvs,
\end{equation*}
that is measurable with respect to the $\sigma$-algebra generated by the open sets
of $\tvs$. This $\sigma$-algebra is known as the Borel $\sigma$-algebra for $\tvs$.
The triple $(\Omega,\mathscr{F},P)$ is a probability space as in Definition \ref{dfnprobabilitytriple}. 
We use the shorthand notation  $X\in\tvs$ whenever the random variable $X$ takes values in $\tvs$. 
For example if $\tvs=L^{2}(\mathbb{R})$,  then  $X\in L^{2}(\mathbb{R})$ means that $X$ is a measurable
map from the probability space $(\Omega,\mathscr{F},P)$ into $L^{2}(\mathbb{R})$.

We say that a random variable $X\in\tvs$ is called Gaussian if $\langle h,X\rangle$ is
a Gaussian random variable on the real line for all $h\in\tvs^{*}$. We say that an element $a\in\tvs$ is the 
expectation of $X\in\tvs$ if 
\begin{equation*}
\E(f,X)=\langle f, a\rangle,\qquad\text{for all }f\in\tvs^{*}.
\end{equation*}
Also a linear and positive definite operator $K:\tvs^{*}\longrightarrow \tvs$ 
is called the covariance operator (e.g. covariance
matrix in the finite dimensional case) if
\begin{equation*}
cov(\langle f_{1},X\rangle,\langle f_{2},X\rangle)=\langle f_{1},Kf_{2}\rangle,
\end{equation*}
for all $f_{1},f_{2}\in\tvs^{*}$. Then we say that $X$ is distributed as 
$\mathcal{N}(a,K)$. It is worth mentioning
that given a covariance operator $L$ and an element $b\in\tvs$ the distribution $\mathcal{N}(b,L)$
does not always exist. But if it does exist, the  Gaussian measure $\mathcal{N}(a,K)$, is completely
identified with $a$ and $K$.
\newline

%%%%%%%%%%%%%%%%%%%%%%%Think about this bit %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%with the construction of a rigorous framework that allows us to talk about gaussian distributions in 
%function spaces we can see why once the covariance function and the mean function are defined then we 
%have created a Gaussian distribution over some function of spaces and why the nature of the function
%space depends heavily on the regularity properties of the covariance kernel. 

%%%%%%%%%%%%%%%%%This is also you need to think about %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%What is the connection between K and a covariance function k(x,x')?%%%

%In this work we are going to be mainly concerned to work with kernels that are at least continuous
%(For example the SE kernel in equation (\ref{eqnsquareexponential}) is $C^{\infty}$). 
As an example consider the  $\tvs=C(T)$ where 
$T$ is compact subset of $\mathbb{R}^{n}$. This is the  space of real valued continuous functions 
on
$T$. This  is a Banach
space with the norm \cite{bressan1900lecture}
\begin{equation*}
\|h\|=\max_{x\in T}|h(x)|.
\end{equation*}
The dual space of $\tvs$ is given by $\tvs^{*}=\mathbb{M}(T)$ the set of signed measures defined on 
the Borel $\sigma-$ algebra of  $T$. In this 
case the duality pairing is given by 
\begin{equation*}
\langle\mu,g \rangle=\int_{T}gd\mu.
\end{equation*}
A GP,  $\{g(t)\}_{t\in T}$ (see definition \ref{dfnGP}) with mean function $m(t)$ and 
covariance kernel $k(t,t')$, can be thought of as a Gaussian measure $\mathcal{N}(m,K)$
where
\cite{lifshits2012lectures} 
\begin{eqnarray*}
\E(f)=m\in\mathbb{C}(T), \\
(K\nu)(t)=\int_{T}k(t,t')d\nu(t'),\qquad\text{for }\nu\in\mathbb{M}(T).
\end{eqnarray*}

The above example shows the connection between GPs and distribution over function spaces. More
precisely how it is connected to Gaussian measures in function spaces. Now we 
explain how to use GPs in a practice.

Assume  we have some  data $\{(\textbf{x}_{i},y_{i})\}_{i=1}^{m}\subset\mathbb{R}^{n}\times\mathbb{R}$ 
 from an expensive function  $M(\cdot)$, 
, where $M(\textbf{x}_{i})=y_{i}$. The set $\{(\textbf{x}_{i},y_{i})\}_{i=1}^{m}$ is called
\textit{training set}. For
simplicity we assume no trend in the \textit{training outputs} $\{y_{i}\}_{i=1}^{m}$. Given the training set
we would like to infer  possible values of $M(\cdot)$ on another set of points 
$\{\textbf{x}_{j}^{*}\}_{j=1}^{k}$. This set of points  is known as \textit{test set}.
For this purpose we construct an emulator $\widehat{M}(\cdot)$ (see introduction to section 2.1).
To construct $\widehat{M}(\cdot)$  we  start considering the GP denoted by $\{f(\textbf{x})\}_{\x\in dom(M)}$
 where $dom(M)$ 
is  the domain of $M(\cdot)$.
 By
Definition \ref{dfnGP}, the random vectors
\begin{eqnarray*}
\textbf{f}=\begin{bmatrix}f(\textbf{x}_{1}) & \ldots & f(\textbf{x}_{m}) \end{bmatrix}^{T}, \\
\textbf{f}^{*}=\begin{bmatrix}f(\textbf{x}_{1}^{*}) & \ldots & f(\textbf{x}_{l}^{*}) \end{bmatrix}^{T},
\end{eqnarray*}
are  jointly Gaussian, i.e. 
\begin{equation}\label{eqnconditional}
\begin{bmatrix}
\textbf{f} \\
\textbf{f}^{*}
\end{bmatrix}\sim\mathscr{N}\left(0,\begin{bmatrix} K(X,X) & K(X,X^{*}) \\
						    K(X^{*},X) & K(X^{*},X^{*}) \end{bmatrix}
\right),
\end{equation}	
where the zero mean models the assumption of no trend in the training output $\{y_{i}\}_{i=1}^{m}$.
Here
$(K(X,X))_{ij}=cov(f(\x_{i}),f(\x_{j})), K(X,X^{*})_{ij}=cov(f(\textbf{x}_{i}),f(\x_{j}^{*}))$ and so on.


By the requirements of Defintion \ref{dfnEmulator},
 the realization of the random vector $\textbf{f}$ is known and is equal to $[y_{1},\ldots,y_{m}]^{T}$.  
and we want to  infer  the vector $\textbf{f}_{*}$.
This can be achieved by obtaining the distribution of $\textbf{f}_{*}|\textbf{f}$. By well known properties
of the multivariate Gaussian distribution we  obtain  \cite{lifshits2013gaussian}
\begin{equation}\label{eqnformulameancovariance}
\textbf{f}^{*}|\textbf{f}\sim\mathscr{N}(\langle\textbf{f}\rangle,\Sigma),
\end{equation}
where
\begin{align*}
&\langle\textbf{f}\rangle=K(X^{*},X)K(X,X)^{-1}\textbf{f}\\
&\Sigma=K(X^{*},X^{*})-K(X^{*},X)K(X,X)^{-1}K(X,X^{*}).
\end{align*}
Note that  if in the above equations, we only consider just one  test point, $\x^{*}$ and
we take the limit as $\x^{*}$ approaches  to the training input $\x_{j}$,
 the matrix
$K(\x^{*},X)$ is now a vector and  converges to  $K(\x_{j},X)$. In this case, it is not hard 
to see that the mean
would be given by 
\begin{equation}\label{eqnExactPrediction}
K(\x_{j},X)K(X,X)^{-1}\textbf{f}=y_{j}.
\end{equation} 
The covariance matrix would 
be an scalar  that tends to zero as $\x^{*}\rightarrow \x$. The interpretation is that 
at a training input $\x_{j}$ the prediction is exactly the  corresponding training output $y_{j}$. 
For a point $\textbf{x}^{*}$ that is not part of the training set, with $95\%$ of confidence we have
\begin{equation}\label{eqnConfidence}
M(\x^{*})\in [\langle f \rangle(\x^{*})-2\sigma,\langle f\rangle(\x^{*})+2\sigma],
\end{equation}
where
\begin{align*}
&\langle f\rangle(\x^{*})=K(\textbf{x}^{*},X)K(X,X)^{-1}\textbf{f}&&\text{(Mean at point $\x^{*}$)}  \\
&\sigma^{2}=K(\textbf{x}^{*},\textbf{x}^{*})-
K(\textbf{x}^{*},X)K(X,X)^{-1}K(X,\textbf{x}^{*}) &&\text{(Variance at point $\x^{*}$)}.
\end{align*}
Equations (\ref{eqnExactPrediction}) and (\ref{eqnConfidence})  show that if we define 
\begin{equation}\label{eqnDefEmulator}
\widehat{M}(\x^{*}):=\langle f\rangle(\x^{*}), 
\end{equation}
then $\widehat{M}(\cdot)$ satisfies the 
conditions for an emulator as in Definition \ref{dfnEmulator}.

In Figure \ref{figChp2}, it is shown an example that summarizes the discussion above.
We consider the problem of emulating the model $M(x)=\cos(2\pi x)$ (dashed-dotted line)
having five training points (black dots). The 95\% confidence region (dashed lines)
shows that in the training input $\x_{j}$  the variance is zero  and $\widehat{M}(\x_{j})=y_{i}$, 
as predicted by equation (\ref{eqnExactPrediction}).
\newline

The covariance kernel is the quantity that defines the mean and covariance for
the Gaussian distribution obtained when we look at finitely many random variables in 
a Gaussian Process. Therefore choosing it
is a crucial step in the fitting process. We now proceed to briefly talk about the properties
of kernels and how to choose them depending on the data and the smooth properties we are looking
for in the emulation process. 

\subsubsection*{Covariance Kernels}
The covariance kernel cannot be any arbitrary function $k(\x,\x^{*})$. To see why, consider  the
matrix in  equation (\ref{eqnconditional}) given by
\begin{equation*}
C:=\begin{bmatrix} K(X,X) & K(X,X^{*}) \\
 K(X^{*},X) & K(X^{*},X^{*}) \end{bmatrix}.
\end{equation*}


This is the covariance matrix of a multivariate Gaussian distribution and is obtained by evaluating
the covariance kernel at different points. The matrix $C$ has to be  symmetric and  positive definite 
for any set of training and test inputs. This implies that the covariance kernel has to be symmetric,
that is, for all $\x,\x'$ in its domain we have
\begin{equation*}
k(\x,\x')=k(\x',\x).
\end{equation*}
We also need that, for  any set of inputs $\{\x_{i}\}_{i=1}^{n}$  the Gram  matrix defined by 
$K_{jk}:=k(\x_{j},\x_{k})$, to be positive definite. If also $k$ is just a function of $\x-\x'$,
then $k(\cdot,\cdot)$ is said to be $\textit{stationary}$.

To understand the role of the covariance kernel in the continuity and differentiability
 of the mean function, let us
define some concepts first. 
\begin{definition}
Let $\y,\x_{1},\x_{2},\ldots$ be a sequence of points in $\mathbb{R}^{n}$, such that 
\begin{equation*}
\|\x_{n}-\y\|_{2}\rightarrow 0\qquad\text{as }n\rightarrow\infty.
\end{equation*}
Then the collection of real valued random variables $\{f(\x)\}$ defined in a probability space
$(\Omega,\mathscr{F},\p)$ are say to be continuous in the mean
square at the point $\y$ if 
\begin{equation*}
\E(|f(\x_{n})-f(\y)|^{2})\rightarrow 0\qquad\text{as } n\rightarrow\infty,
\end{equation*}
where
\begin{equation*}
\E(f(x)):=\int_{\Omega}f(x)d\p.
\end{equation*}
\end{definition}
We also have a definition for differentiability
\begin{definition}
The mean square derivative of the  collection $\{f(\x)\}$  it the $i-th$ direction  at a point $y$ is
\begin{equation*}
\frac{\partial f(\y)}{\partial x_{i}}=
\lim_{h\rightarrow 0}\E\left(\left|\frac{f(\y+h\textbf{e}_{i})-f(\y)}{h}\right|^{2}\right),
\end{equation*}
where $\textbf{e}_{i}$ is the $i$-th canonical vector of the standard basis in $\mathbb{R}^{n}$.
The mean square $n$-th derivative is given by 
\begin{equation*}
\frac{\partial^{n} f(\y)}{\partial x_{i}^{n}}=
\lim_{h\rightarrow 0}\E\left(\left|\frac{\frac{\partial^{n-1}f(\y+h\textbf{e}_{i})}{\partial x_{i}^{n-1}}-
\frac{\partial^{n-1}f(\y)}{\partial x_{i}^{n-1}}}{h}\right|^{2}\right),
\end{equation*}
whenever the limit Exists.
\end{definition}


For Gaussian processes $\{f(\x)\}$ with stationary covariance kernel it can be showed that 
the process is continuous in the mean at a point $\y$ if and only if $k$ is continuous at $(\y,\y)$. 
Also the kernel function for the $n$-th derivative is given by \cite{adlergeometry}
\begin{equation*}
\frac{\partial^{2n}k(\x,\x')}{\partial^{2}x_{1}\ldots\partial^{2}x_{m}'}.
\end{equation*}
Therefore the continuity and differentiability properties of the mean function in a Gaussian process
depends exclusively in the continuity and differentiability properties of the covariance kernel.


Another important aspect of covariance kernels is that they are  defined in terms of parameters. 
The way we choose the values of these parameters in practice, is based on the data
we are analyzing. To see how this works, let us return to the problem of of approximating $M(\cdot)$
by $\widehat{M}(\cdot)$ using Gaussian processes. Let   $k(x,x';\theta)$ be the covariance
kernel for the GP that depends on the parameter $\theta$ 
($\theta$ could be a scalar, vector, etc.). In this case to predict the output
$\y^{*}=\{M(\x_{1}^{*}),\ldots M(\x_{m}^{*})\}$ given the training set $\{(\x_{i},y_{i})\}_{i=1}^{m}$, 
we can try different approaches. On of the most common is maximum likelihood optimization (MLE). 
Mathematically, we pick a parameter $\hat{\theta}$ such that
\begin{equation*}
\hat{\theta}=\argmax_{\theta}\p(\y^{*}|\{(\x_{i},y_{i})\}_{i=1}^{m},\theta).
\end{equation*}
By Definition \ref{dfnGP} we know that the conditional probability for $\y^{*}$ has to be distributed as
a multivariate Gaussian distribution. More precisely

\begin{equation}\label{eqnlikelihoodExponential}
p(\y^{*}|\{(\x_{i},y_{i})\}_{i=1}^{m},\theta)=\frac{1}{(2\pi)^{\frac{m}{2}}det(K_{\y^{*}}(\theta))^{\frac{1}{2}}}
e^{-\frac{1}{2}(\y^{*T}K_{\y^{*}}(\theta)^{-1}\y^{*})}.
\end{equation}
Where $K_{\y^{*}}(\theta)$ is the matrix $K(X,X)$ in equation (\ref{eqnconditional}). 
To find the value of $\hat{\theta}$  We have to maximize (\ref{eqnlikelihoodExponential})
with respect to $\theta$.
This goal is unchanged if we take logarithm on  both sides and minimize the following
function instead\footnote{The reason to do this is because most
software packages for optimization, search for the minimum not the maximum.}


\begin{equation}\label{eqnloglikelihood}
L(\theta)=-\log(p(\y^{*}|\{(\x_{i},\y_{i})\}_{i=1}^{m},\theta))=\frac{1}{2}\y^{*T}K_{\y^{*}}(\theta)^{-1}\y^{*}+
\frac{1}{2}\log|K_{\y^{*}}(\theta)|.
\end{equation}

A minimizer of $L(\theta)$   gives  a possible value for $\hat{\theta}$
that explains the best the data $\y^{*}$ given the training set $\{\x_{i},y_{i}\}_{i=1}^{m}$.  
Another common way to tune in the parameters
is using  $K$-fold cross validation. We will not use this approach here, the interested
reader is referred to \cite{murphy2012machine} for details.
\newline

So far we have not discussed  how to choose the training inputs $\{\x_{i}\}_{i=1}^{m}$. 
Clearly this choice has a profound  impact in the quality of the accuracy of the emulator.
To see this, let us assume that the function $M(\cdot)$ is supported in $[0,1]$ and we  have
computational resources to calculate the output of only five training
points. If we pick the points $\{0,0.1,0.2,0.3,1\}$ the interpolation error of the emulator
$\widehat{M}(\cdot)$  for points between $0.3$ and $1$, 
is going to be big, compared to the error associated with the partition $\{0,0.25,0.5,0.75,1\}$ as
shown below
\begin{figure}[H]
\raggedleft
\includegraphics[scale=0.33]{./FigChap2/partitionComparison}
\caption{Comparison between the approximation quality of the emulator $\widehat{M}$ for 
for the model $M(x):=\cos(2\pi x)$ in the interval $[0,1]$ for two different partitions. 
On the left, the emulation is performed in the partition $\{0,0.25,0.5,0.75,1\}$. On
the right in the partition $\{0,0.1,0.2,0.3,1\}$.}
\label{figChp2}
\end{figure}
 




Ideally we would like to pick as many training points as possible to make the fitting better, 
but picking too many points
to create the training set, might result in a very high computational demand. On the other hand if we pick up
just few points to create the training set, then it is possible to end up with unreliable predictions. 
Thus we need a systematic way to choose  the training points. One strategy is to  
 fill as much of the space as possible given a fix number (possibly small) of  training points. 
This can be accomplish
through    space filling designs which we will now discuss. 
\newline

%%%Sensitivity. The first paragraph should be relocated
\subsection{Design of Experiments }\label{secDesignofExperiments}

%Besides uncertainty there is another very important concept: sensitivity. When looking at a  model's performance
%it is critical to assess how changes or uncertainties 
% in the input $x$ affect the output $y$. Therefore if we assess sensitivity
%of the model we can assess uncertainty of the outputs. One more reason one might be interest in performing
%a sensitivity analysis is to detect what variables are relevant and what variables are not, allowing to reduce
%the dimensionality of the problem .

% To interpolate the data obtained from evaluating the computationally expensive function
%$M(\cdot)$ using GPs, we need to decide in how many different points are we going to evaluate $M(\cdot)$. 
%As mentioned in the previous section this is a very delicate issue since we need to find 
%the right balance between
%the number of possible evaluations of $M(\cdot)$ given time, computational budget 
% and a good spread of data points in the space to get a good
%fit to the model.

We assume there is a fixed computational budget. In this case we need to decide how
to choose the training inputs $\{\x_{j}\}_{j=1}^{m}$ to obtain reliable predictions 
of the emulator for points
different than the training points. As shown in Figure \ref{figChp2}, the quality
of the emulation depends heavily on the distribution of the training inputs. 
Intuitively we want to spread the training inputs as much as possible in the
parameter space while covering  as much space as possible. 
Distributions of points that achieve this are called \textit{space filling designs}.
\newline
 
Given an set $T\subset\mathbb{R}^{n}$, there are several ways to create space filling designs. 
In this work we are going to focus on maximin designs
\cite{johnson1990minimax}. We note that there are other ways to obtain space filling
designs and we refer to the reader to  \cite{pronzato2012design}. Consider a metric space $(T,d)$ (e.g.
$T\subset\mathbb{R}^{n}$, compact and $d$ the Euclidean distance) and a subset $S$ of $T$, 
with finite (fixed) cardinality, say $|S|=n$.
A maximin distance design $S^{o}$ is a collection of points of $T$  such that
\begin{equation*}
\max_{S\subset T,\text{ }|S|=n}\min_{s,s'\in S}d(s,s')=\min_{s,s'\in S^{o}}d(s,s')=d^{o}.
\end{equation*}
That is, we are looking for a set $S^{o}$ of cardinality $n$ that maximizes the minimum distance among 
its elements. As an example consider $T=[0,1]^{3}$, the unit cube in $\mathbb{R}^{3}$ and $n=8$. In 
this case the design that maximizes the minimum distance among its elements is given by choosing
 the 8 vertices of the cube. Or as shown if Figure \ref{figChp2}, right, if $T=[0,1]$ and $n=5$, 
the maximin design is given by a uniform partition  of the set $T$.


The problem of finding
the optimal  maximin design is difficult to solve. In practice we use computational tools
to find a design that is close to optimal.  Different kind of algorithms can be used for the optimization
of the design, such as genetic algorithms, simulated annealing, particle swarm, etc. A survey
on the subject  can be found in 
\cite{viana2010algorithm}. In Chapter 4 we will see how  the particle swarm algorithm can be used to 
create a maximin design in a five dimensional parameter space.

To conclude this section, we note that there is a conection between maximin designs and Gaussian processes. 
Consider a
GP $\{f(x)\}_{x\in T}$. If we fix $S=\{s_{1},\ldots,s_{n}\}\subset T$  and consider the random vector
\begin{equation*}
\textbf{f}=[f(s_{1}),\ldots,f(s_{n})],
\end{equation*}
where $\textbf{f}$ is assumed to be jointly Gaussian. Let $K_{s}$ be 
the correlation matrix for the probability distribution of $\textbf{f}$. Then it can be shown
that the minimax design minimizes the quantity 
\begin{equation*}
D(S)=-det(K_{s}).
\end{equation*}
This matrix is the same as the covariance matrix in equation (\ref{eqnconditional}).
A survey on the theory behind maximin distance designs can be found in \cite{johnson1990minimax}.
\newline


%ince the covariance matrix is positive definite (hence the correlation matrix is also positive definite)
%, then $det(K_{s})>0$. By minimizing the  negative of the determinant  we are maximizing
% the determinant. This is achieved when the column vectors of a matrix
%are orthogonal. 


\subsection{Sensitivity Analysis}


In general having an space filling design for the training input, permits to create an
emulator $\widehat{M}(\cdot)$ that closely approximates $M(\cdot)$  over its whole domain. 
By closely we mean a tolerable uncertainty in the output of the emulator 
for all points in the domain (see Figure \ref{figChp2}).
%Let us suppose that we have a good space filling design, we can construct a good GP, in the sense that 
%the uncertainty in the interpolation is less compared to the interpolation error when
%using other space filling design. 
%then we have a good fit when using gps to interpolate  the 
%points we want to get information about. 
If we have a reliable fitting we can confidently assess what arguments in the model $M(\cdot)$
are relevant and which ones are not.
This allows to approximate  the model  with a simpler one.
For example, if our model is given by 
\begin{equation*}
M(x_{1},x_{2},x_{3})=x_{1}+x_{2}+10^{-8}x_{3},\qquad(x_{1},x_{2},x_{3})\in  T=[0,1]^{3}.
\end{equation*}
Clearly the variable $x_{3}$ is not as relevant as $x_{1}$and $x_{2}$. We need to
formalize in what sense $x_{3}$ is irrelevant. One way to achieve this is by doing a 
sensitivity analysis. In summary, the goal of 
sensitivity analysis is to assess how
the output of a function $M(\cdot)$ depends on variations of its arguments. There is
a great number of methods to do a sensitivity analysis, such as adjoint methods, local
methods, variance based methods, etc. to name a few. The difference of each of these
methods is how they measure the importance of each variable. For example in local methods,
the sensitivity at a point in a given direction is the slope of the function, whereas in
variance based method what matters is how large is the area under the curve when
fixing all parameters but one.
For a survey of techniques in sensitivity analysis, 
the reader is referred to \cite{saltelli2000sensitivity}. In this work we  use 
variance-based Monte Carlo methods (VBMCM) described in \cite{sobol1993sensitivity}.
The idea of  VBMCMs is to use the variance produced by  the inputs of a function as an indicator of 
their importance. More precisely we are going to use the method of Sobol'. We now explain
the main ideas behind this method.


The functions of interest in this work have compact support. This implies that
without loss of generality we may assume that  the domain of these functions 
is the $n$-dimensional unit cube $\Omega^{n}$. Let us consider a generic
square integrable function
\begin{equation*}
\varphi:\Omega^{n}\rightarrow\mathbb{R}.
\end{equation*}
We start by decomposing $\varphi$ as 
\begin{equation*}
\varphi(x_{1},\ldots,x_{n})=\varphi_{0}+\sum_{k=1}^{n}\varphi_{k}(x_{k})+
\sum_{1\leq k< l\leq n}\varphi_{kl}(x_{k},x_{l})+\ldots+
\varphi_{1,2,\ldots,n}(x_{1},\ldots,x_{n}).
\end{equation*}
This decomposition is not unique, but it can be shown that if each term $\varphi_{i_{1},\ldots,i_{j}}$
in the expansion satisfy

\begin{equation}\label{eqnSobolCond1}
\int_{[0,1]}\varphi_{i_{1},\ldots,i_{j}}dx_{i_{k}}=0\qquad\text{if }  i_{k}\in \{i_{1},\ldots,i_{j}\},
\end{equation}
then the decomposition is unique and all terms in the expansion are orthogonal in $L^{2}(\Omega^{k})$. To 
see the orthogonality property, 
we may  consider the functions $g=\varphi_{i_{1},\ldots,i_{j}}$ and $h=\varphi_{l_{1},\ldots,l_{k}}$ 
with arbitrary indices $(i_{1},\ldots,i_{j})\neq(l_{i},\ldots,l_{k})$. Without 
loss of generality we may  assume $i_{1}\neq l_{1}$. In this case we have
%by Fubinni's theorem \cite{lerner2014course} we may conclude that functions with different subindices are 
% pairwise orthogonal in $\Omega^{n}$ with the standard inner product of $\mathbb{R}^{n}$\cite{bressan1900lecture}. 
%To see this, without loss of generality
%we may  consider the functions $g=\varphi_{i_{1},\ldots,i_{j}}$ and $h=\varphi_{l_{1},\ldots,l_{k}}$ 
%with $(i_{1},\ldots,i_{j})\neq(l_{i},\ldots,l_{k})$, with $i_{1}\neq l_{1}$. In this case we have
\begin{equation*}
\langle g,h\rangle=\int_{[0,1]}\ldots\int_{[0,1]}\underbrace{\left(\int_{[0,1]}\varphi_{i_{1},
\ldots,i_{j}}dx_{i_{1}}\right)}_{\text{$=0$ by (\ref{eqnSobolCond1})}}
\left(\int_{[0,1]}\varphi_{l_{1},\ldots,l_{k}}dx_{l_{1}}\right)dx_{\sim i_{1},l_{1}}=0,
\end{equation*}
where we used Fubinni's theorem to split the integrals \cite{lerner2014course}. The symbols to the right of $\sim$ 
represent the variables omitted in the integration.

Another consequence of  (\ref{eqnSobolCond1}) is 
\begin{eqnarray*}
\int_{\Omega^{n}}\varphi dx=\varphi_{0}.
\end{eqnarray*}

This allows us to find  the other functions in the decomposition recursively,
given $\varphi_{0}$. For example 
for $i\in \{1,\ldots,n\}$ we have
\begin{equation*}
\varphi_{i}(x_{i})=-\varphi_{0}+\int_{[0,1]^{n-1}}\varphi(x)dx_{\sim i}.
\end{equation*}
Having $\varphi_{i}(x_{i})$ we can proceed to find $\varphi_{ij}(x_{i},x_{j})$ using
\begin{equation*}
\varphi_{ij}(x_{i},x_{j})=-\varphi_{0}-\varphi_{i}(x_{i})-\varphi_{j}(x_{j})+
\int_{\Omega^{n-2}}\varphi(x)dx_{\sim ij}.
\end{equation*}

By knowing all of
the functions in the decomposition of $\varphi$ we are able  to assess how each variable 
affects the output of $\varphi$ in the following way: the total variance $D$ of $\varphi$ is defined as
\begin{equation*}
D=\int_{\Omega^{n}}\varphi^{2}(x)dx-\varphi_{0}^{2}.
\end{equation*}
Similarly we can compute the partial variances as
\begin{equation*}
D_{i_{1},\ldots,i_{s}}=\int_{[0,1]^{n-1}}\varphi^{2}_{i_{1},\ldots,i_{s}}dx_{i_{1}}\ldots dx_{i_{s}}.
\end{equation*}
With these variances we define the $s$-th order  Sobol index  
\begin{equation*} 
S_{i_{1},\ldots,i_{s}}=\frac{D_{i_{1},\ldots,i_{s}}}{D}\qquad\text{(Sobol' Index of Order s)},
\end{equation*}
which is a measure of the contribution of the variables $x_{i_{1}},\ldots,x_{i_{s}}$ to the total variance $D$.
If we want to know the separate effect  of each variable
$x_{1},\ldots,x_{n}$ in the total variance $D$, we look at
the first order Sobol indices $S_{1},\ldots,S_{n}$ given by
\begin{equation*}
S_{i}=\frac{D_{i}}{D},\qquad\text{for }i=1,\ldots,n.
\end{equation*}

Finally if we want to assess the full effect of a  variable  in the total variance $D$, 
we calculate a quantity known 
as the total effect index. For example if we want to calculate the total effect index
for the variable $x_{i}$ we would do so by calculating
\begin{equation*}
S_{i}+S_{i1}+S_{i2}+\ldots+S_{i12}+S_{i13}+\ldots+S_{12\ldots,i,\ldots, n}.
\end{equation*}

Note that  to calculate each of the Sobol indices, it is necessary to do 
high dimensional integrals. Therefore integration using quadratures is not possible.
It is necessary to resort to other numerical integration techniques. A common
tool to perform high dimensional integrals is known as Monte Carlo integration. We will not
go into details of Monte Carlo integration in this chapter, we postpone them for Chapter 3.
What is important at this time is that to apply Monte Carlo integration, it is necessary to 
evaluate the integrand a high number of times at different points in its domain. If the 
integrand is the expensive model $M(\cdot)$, then the computational cost of estimating
the Sobol' indices is prohibitive. If instead we calculate the Sobol' indices 
of the emulator $\widehat{M}(\cdot)$, we can use them as an approximation for the Sobol'
indices of $M(\cdot)$. In this way we can estimate what arguments of the model are 
relevant and what arguments are not. This will allow us to reduce the complexity of the
model.

In the next chapter we are going to show how to the theory explained in  this chapter
can be used in a practical setting using a toy problem. In Chapter 4 we 
proceed to apply the tools developed here to the problem explained in Chapter 1.


%%Talking about R packages
%\newpage
%\subsection{R packages}
%In this work we used two different R packages. One to do the fitting with GPs (DiceKriging) and the other to do 
%a sensitivity analysis using Sobol Indices (Sensitivity). We are going to briefly describe both of this packages.
%
%\subsubsection{Package: DiceKriging}
%According the description of the package (http://dice.emse.fr/) it is used for Estimation, validation and 
%prediction of GP models.
%
%The way this package works is as follows. First it creates an element of the class `km' by receiving 
%as an input a trending formula, the set of training points $(x_{i},f_{i})$ and a choice 
%of a covariance kernel. The kernels available are: Gauss, Exponential, Matern $\frac{3}{2}$
%,Matern $\frac{5}{2}$ and power exponential. It is also possible to work with tailored covariance
%kernels but we won't explore that possibility. Once the `km' object is created we can do 
%predictions on test points $x^{*}$ 
%by using the function predict. Predict takes as an input a km object, the set of test points and 
%some other optional parameters. Gives as an output an R list that contains the estimation of $f(x^{*})$
%using the mean of the $GP$ and the lower and upper 95\% confidence interval using the 
%covariance matrix (see equation (\ref{eqnformulameancovariance})).
%One of the nice feature that the DiceKriging package has is that once you choose a kernel, you don't
%have to set the parameters of the kernel chosen. Using an optimization routine the function
%predict chooses the best combination
%of parameters through a Maximum Likelihood Optimization \cite{dupuy2015dicedesign} (see \ref{eqnloglikelihood}).
%
%
%\subsubsection{Package: Sensitivity}
%The main function we used was the function SobolGP. This function takes as its main   input an object 
%from the class `km' A matrix representing a sample of random points in the domain of the function $f$
%we want to calculate its sensitivity (this function $f$ was previously 'fitted' by the function
%km in package DiceKriging) and the main output are two lists. One lists that contains 
%all the results for the GP-based sensitivity analysis for the main effect and one list with the 
%results for the GP-based sensitivity analysis for the total effects.
%
% 
%
%For the next chapter we are going to explain how to use in a toy problem all of this tools explained in this 
%chapter, so for chapter four we can focus on the results instead on how we applied what was explained here. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Toy Problem: How Theory Works in Practice}

In the previous chapter we reviewed some  of the theoretical and computational tools needed to solve
a Bayesian inverse problem. In this chapter
we are going to present  a toy problem to illustrate how the theory  can be applied in practice.
We begin by considering the forward problem, given by the following partial differential equation (PDE).

\begin{equation}\label{eqntoyproblem}
\left\{
	\begin{array}{ll}
		\Delta u=e^{-b\|\x\|_{2}}, &\mbox{for } x\in\Omega=[0,1]\times [0,1]\subset\mathbb{R}^{2}, \\
		u=0, & \mbox{for } x\in\partial\Omega,
	\end{array}
\right.
\end{equation} 
where $b$ is some real positive parameter. The 
function $u$ represents the mathematical approximation of  a quantity $\tilde{u}$ that has a physical interpretation. The  behavior
of $\tilde{u}$ is assumed to be    modeled by equation (\ref{eqntoyproblem}).

In Chapter 2 Section 2.1, we explained how to build an emulator $\hat{M}(\cdot)$  that approximates
the output $y$  of a computationally expensive function  $M(\cdot)$ at a point  in its domain. 
In  this chapter, the function $M(\cdot)$ takes as input a point  $(\textbf{x},b)\in\Omega\times(0,\infty)$. The
output is the value of the solution $u$ at that 
point, i.e. $u(\textbf{x};b)=M(\textbf{x},b)$. Now we proceed to explain the associated inverse problem and  how we are going to construct $\hat{M}(\cdot)$.  

Assume that we have ten experimental measurements 
of $\tilde{u}$. These measurements were taken  at the points $P:=\{\x_{1},\x_{2},\ldots,\x_{10}\}\subset\Omega$. 
That is, we know the vector of measurements 
$\textbf{y}=(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$.
We want to estimate the value of $b$ that explains  the experimental data $\textbf{y}$ the best. 
This is our inverse problem. 
A simple approach to estimate $b$ 
would be to solve equation (\ref{eqntoyproblem}) for a big number of values $b$ in the interval $(0,L]$ where $L$ 
is chosen in a manner that there exists a $b^{*}\in (0,L]$ such that the vector 
$(u(\x_{1};b^{*}),\ldots,u(\x_{10};b^{*}))$
has `small' discrepancy with the experimental data $\y$.
 
Let us assume that solving
equation (\ref{eqntoyproblem}) is computationally expensive and repeating the calculation for a big range of 
different values of $b$
is not feasible. Therefore we need to construct an emulator $\widehat{u}(\cdot)$ that approximates $u(\cdot)$. 
The way we are going to construct $\widehat{u}(\cdot)$ is as follows: for a fixed $\x$ we solve equation 
(\ref{eqntoyproblem}) for   $n$  different values of  $b$. We pick the value of $n$ in a way
that the computational cost of computing (\ref{eqntoyproblem}) $n$ times, does not exceed our
computational and time budget. Then use the data $\{b_{j},u(\x,b_{j})\}_{j=1}^{n}$  as a 
training set to create a Gaussian process, as explained in Chapter 2, Section 2.1.1. Finally
for any value $\tilde{b}$ we use the mean of the Gaussian process at that point as $\widehat{u}(\x,\tilde{b})$.
An sketch from the result for approximating a model $u(\x;\cdot)$ with an emulator
$\widehat{u}(\x;\cdot)$ is shown
in Figure \ref{figGPCreation}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{./FigChap3/emulatorApproximation}
\caption{Approximation of a model $u(\x;\cdot)$ by the mean of a Gaussian process trained
with six  different  outputs from the model. The mean of the Gaussian process at a point $\tilde{b}$ is taken
as the value $\widehat{u}(\x;\tilde{b})$ of the emulator.}
\label{figGPCreation}
\end{figure}

For clarity in the exposition, the table below we summarize the notation 
we are going to use throughout the rest of the chapter.




%Finally use the emulator
%$\hat{M}(\cdot)$ to predict the output of $M(\cdot)$ for as many different values of $b$ as possible. 
%The value of the emulator at the point $(\x,b)$  is going to be denoted by $\hat{u}(\x;b)$. The following
%table summarizes the notation that is going to be used from now on in this Chapter.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline 
Symbol & Meaning \tabularnewline 
\hline 
\hline
\hline 
$\tilde{u}(\x;b)$ & \pbox{7cm}{Value of the physical variable at the point $\x$
with parameter $b$.\\} \tabularnewline 
\hline 
\hline
$u(\x;b)$ & \pbox{7cm}{Numerical solution of equation (\ref{eqntoyproblem})
at $\x$ with parameter $b$.\\} \tabularnewline
\hline
\hline 
$\hat{u}(\x;b)$ & \pbox{7cm}{Value of the interpolation of the emulator $\hat{M}(\cdot)$ at the point $\x$ with parameter
$b$\\}.  \tabularnewline
\hline
\hline 
$P:=\{\x_{1},\ldots,\x_{10}\}$ & \pbox{7cm}{Points where the experimental measurements were taken\\}.  \tabularnewline
\hline
\hline 
$\y:=(\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b))$ & \pbox{7cm}{Values of the experimental measurements for the variable $\tilde{u}$\\}.  \tabularnewline
\hline
\end{tabular}

\caption{Summary of symbols used in Chapter 3.}
\label{tabSymboltable}
\end{table}
Let us return to our original goal,  to estimate the value of $b$ that explains  the experimental data 
$\y$ as best as possible. To create the experimental data $\y$ we 
assume that the true value of $b$ is $0,925$. Then, for this value of $b$,  we solve equation (\ref{eqntoyproblem})
using a finite difference five point  stencil approximation for the Laplacian. 
Next we pick  ten points at random in $\Omega$ and save the value of the numerical 
solution $u$ at those location (see Figure \ref{figsolU}).  Finally we add  noise from
a normal distribution with mean zero and standard deviation $0.01$ to each  of the ten values. 
The resulting numbers  are what we use
as the experimental data $\y={\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b)}$. 
Note that the noise added to the data obtained from the
numerical  solution of equation
(\ref{eqntoyproblem}) plays the role of possible  
errors in the experimental measurements plus inaccuracies of the 
model to describe the true behavior of the physical variable $\tilde{u}$.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./FigChap3/solu}
\caption{Numerical solution of the system (\ref{eqntoyproblem}) using a five points stencil finite difference
approximation for the Laplacian. The mesh
size used in $x$ and $y$ was $0.01$. The value of the parameter $b$ was set at $0.925$. The black dots
in the plot represent the points used to generate the experimental data 
$\y=\{\tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b)\}$}
\label{figsolU}
\end{figure}

Once we have created the experimental data $\y$, to obtain a point estimate value of $b$, it is necessary
to compute the posterior distribution. We are going to explain step by step how to obtain such distribution.

\section{Computing the Posterior}
To calculate the posterior we use Bayes rule to get

\begin{equation} \label{eqnpropto}
\post(b|\y)=\frac{\like(\y|b)\prior(b)}{Z(\y)}.
\end{equation}
Note that finding the posterior enables us to obtain   any of point
estimate from equation (\ref{eqnpointestimates}) and the uncertainty associated with that estimate.
To compute $\post(b|\y)$ we need to choose
a prior distribution and the likelihood for $b$. Let us start with the prior. 

\subsection{Choosing the Prior}

For the sake of
the example let us assume that  it is known that
the parameter $b$ cannot be greater than $2$. In this case one way to choose a prior distribution
for $b$ that does not assume any other knowledge than $b\in (0,2]$, is the \textit{uniform distribution}. 
%With this distribution, given a Borel measurable set $A\subset(0,2]$, the probability that $b$ belongs to $A$ is given by
%\begin{equation*}
%\frac{1}{2}\int_{A}dx.
%\end{equation*}
In this case we have 
\begin{equation}\label{eqnpriortoyproblem}
\prior(b)=\frac{1}{2}\textbf{1}_{(0,2]}(b),\qquad\text{for all $b\in\mathbb{R}$},
\end{equation}
where $\textbf{1}_{(0,2]}$ is the indicator function of the set $(0,2]$. The indicator function for a Borel measurable set $C$ is
defined as
\begin{equation*}
\textbf{1}_{C}(y)=\left\{
	\begin{array}{ll}
		1 & \mbox{if }	y\in C\\
		0 & \mbox{if }   y\in C^{c}.
	\end{array}
\right.
\end{equation*}

\subsection{Finding the Likelihood}
To calculate the likelihood,first we need to know how the set of measurements 
$\y=\{ \tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b)\}$ is related to $b$ when
we let $b$ to vary. To obtain such relation we need to solve
equation (\ref{eqntoyproblem}). By solving  this equation explicitly we can find a functional relation
between $u$ and $b$ for each one of the ten locations depicted in Figure \ref{figsolU}.
It is possible to formally solve equation (\ref{eqntoyproblem}). However
the relation between $u$ and $b$ is  given by an infinite series.  Indeed equation 
(\ref{eqntoyproblem}) is the Poisson's equation with homogeneous boundary conditions. This
equation can be solve using an eigenfunction expansion \cite{logan2014applied}. The
eigenfunctions of the Laplacian in the unit square are given by
\begin{equation*}
\phi_{mn}=\sin(n\pi x)\sin(m\pi y),\qquad\text{for }m,n\in\mathbb{N},\
\end{equation*}
with eigenvalues
\begin{equation*}
\lambda_{mn}=(n\pi)^{2}+(m\pi)^{2}.
\end{equation*}
The eigenfunction expansion  for $u$ in equation (\ref{eqntoyproblem}) is calculated as
\begin{equation*}
u=\sum_{n=1}^{\infty}\sum_{m=1}^{\infty} a_{mn}\phi_{mn}
\end{equation*}
where
\begin{equation}\label{eqnIntegrals}
a_{mn}\lambda_{nm}=-\frac{\int_{\Omega}e^{-b\|x\|^{2}}\phi_{mn}d\x}{\int_{\Omega}\phi_{mn}^{2}d\x}=
-\frac{\langle e^{-b\|x\|^{2}},\phi_{mn}\rangle}{\|\phi_{mn}\|_{L^{2}(\Omega)}^{2}}.
\end{equation}
The symbol $\langle\cdot,\cdot\rangle$ is the standard inner product in $L^{2}(\Omega)$.


Having a functional relation given
by an infinite series is often not very useful. For example in equation (\ref{eqnIntegrals})
the integral on the numerator does not have a closed form.
Hence we need a different approach to gain insight into the relation between $\y$ and $b$. 
The  approach  we will use is the  same as the one that allowed us to obtain
Figure \ref{figGPCreation}.  First we solve equation (\ref{eqntoyproblem}) for
$n$ different values of $b$. For the sake of the example assume $n=10$. Then 
for each $\x$ in $P=\{\x_{1},\ldots,\x_{10}\}$ use the
set $\{b_{j},u(\x_{k};b_{j})\}_{j=1}^{10}$ to train a Gaussian process for each $k=1,2,\ldots,10$.
Finally for any $\tilde{b}\in (0,2]$ use the mean of the Gaussian process at that point as
the value $\widehat{u}(\x_{k};\tilde{b})$. By proceeding in this manner we obtain 
a cheap method to approximate  the behavior   of the set 
$\y=\{ \tilde{u}(\x_{1};b),\ldots,\tilde{u}(\x_{10};b)\}$ when we let 
$b$ to vary.

The next step is to choose  the values of $b$  for which the  PDE (\ref{eqntoyproblem}) is solved in a 
way the uncertainty associated with to the emulator is as small as possible. 
We shall denote the points we choose as $\{b_{1},\dots,b_{10}\}$. To choose the points 
we use a maximin design as explained in Chapter 2 Section \ref{secDesignofExperiments}. In this case
it is straightforward to check that the maximin design is the set of equidistant points
\begin{equation*}
\{b_{1}=0.2,b_{2}=0.4,\ldots,b_{10}=2\}.
\end{equation*}
\newline 
Recall that we know the value of $u$ at ten points $P=\{\x_{1},\ldots,\x_{10}\}$.
%We  use  the set of equidistant  points to train a GP for each of the ten sites in $P$. 
Therefore is  necessary to create ten GPs, hence we have
\begin{equation*}
G_{k}:(0,2]\rightarrow\mathbb{R}\qquad\text{for }k=1,2,\ldots 10.
\end{equation*}
such that  for each $k$ and $b$,  the value of the mean of the GP is going to be given by $G_{k}(b)$.
That is, $G_{k}(\cdot)$ is the emulator for $u(\x_{k},\cdot)$. More precisely
\begin{equation*}
G_{k}(b):=\hat{u}(\x_{k};b).
\end{equation*} 


For the interpolation points, we use the same set for all GPs:
\begin{equation*}
\{0.01,0.02,\ldots,1.99,2\}.
\end{equation*}

 
In Figure \ref{fignofitted} are plotted  
the GP regression,  the true value of $b$, the value of $\tilde{u}(\x_{k};b)$ 
and the training data $\tilde{u}(\x_{k};b)$ for each of the ten sites.



%
%We are ready to run the emulator $\hat{f}$ for these values of $b$, get a numerical value at
%the 10 points in the domain where the synthetic data were created (black dots in Figure \ref{figsolU})
%and use GPs to fill the missing information. Take into account that this process of `filling the blanks'
%has to be done in all of the 10 measurement points in the domain $\Omega$ of definition of the phyiscal model.
%
%In Figure \ref{fignofitted} we can see the results from running the emulator (black dots) compared
%with the experimental measurement for each of the 10 sites (black line).

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{./FigChap3/fitted}
\caption{Training points, GP regression, true value of $b$ and experimental measures for each one of the ten sites labeled
from 1 to 10 in Figure \ref{figsolU}}
\label{fignofitted}
\end{figure}



The solid line in Figure \ref{fignofitted} depicts the dependence of  $\hat{u}$ on $b$ for each of the 
ten sites. 


We are now ready to make the mathematical connection between $\tilde{u},u$ and $\hat{u}$. Recall
that $u$ is the mathematical approximation of the physical variable $\tilde{u}$ and $\hat{u}$
is the emulator for $u$. Hence if $\hat{u}$ approximates well $u$, we would expect that 
$\hat{u}$ approximates $\tilde{u}$. For any point $x_{k}\in P$ we don't know exactly
how  $\hat{u}(\x_{k},\cdot)=G_{k}(\cdot)$ differs from $\tilde{u}(\x_{k},\cdot)$.
If we define $y_{k}(b):=\tilde{u}(\x_{k},b)$, then, a possible 
relation
that connects these quantities is given by the following Gaussian additive model (\textbf{cite a reference here})
\begin{equation}\label{eqnreal2interp}
y_{k}(b)=G_{k}(b)+\epsilon_{k},\qquad\text{with } \epsilon_{k}\sim\mathcal{N}(0,\lambda^{2}),
\end{equation}
where $\lambda$ is  a positive number that models how much we believe  the emulator prediction differs from $\tilde{u}$. 
We chose the value $\lambda=5.4\times 10^{-3}$ to get a signal to noise ratio  of 1:10.
By defining the vector  
$\textbf{G}(b)=(\hat{u}(\x_{1};b),\ldots,\hat{u}(\x_{10};b))$ and  the definition of $\y$ 
(see table \ref{tabSymboltable}). Then equation (\ref{eqnreal2interp}) can we written more compactly as
\begin{equation}\label{eqnvector2interp}
\textbf{y}=\textbf{G}(b)+\epsilon,\qquad\text{with }\epsilon\sim\mathcal{N}(0,\lambda^{2} I_{10\times 10}).
\end{equation}


Since the random vector $\epsilon$ has a Gaussian distribution, we can use equation (\ref{eqnvector2interp})
to conclude 
\begin{equation*}
\textbf{y}|b\sim \mathcal{N}(\textbf{G}(b),\lambda^{2} I_{10\times 10}),
\end{equation*}
i.e.
\begin{equation}\label{eqnlikelihoodtoyproblem}
\p(\textbf{y}|b)\propto e^{-\frac{1}{2\lambda^{2}}\|\textbf{G}(b)-\textbf{y}\|_{2}^{2}},
\end{equation}
where the proportionality constant normalizes the distribution on the right hand side to one. Since
the denominator in Bayes' rule (\ref{eqnpropto}) is independent of $b$, 
we can use equations (\ref{eqnpriortoyproblem}) and (\ref{eqnlikelihoodtoyproblem})  
to write 
\begin{equation}\label{eqnposteriorforb}
\post(b|\y)\propto\like(\y|b)\prior(b)\propto \textbf{1}_{(0,2]}(b)e^{-\frac{1}{2\lambda^{2}}\|\textbf{G}(b)-\textbf{y}\|_{2}^{2}}.
\end{equation}
An interpretation of this result is that before taking experimental measurements  we only knew 
that $b\in (0,2]$. After weighting this prior belief with the data $\y$, our current state of knowledge about the
parameter $b$ is encoded in the posterior distribution. Figure \ref{figlikeprior} shows this updated distribution.
%
%As we can see in Figure \ref{fignofitted}, the emulator sometimes overestimates the value of $b$ and sometimes
%underestimates it, this behaviour is expected. The hope is that this inaccuracies oscilate around the true
%value of $b$.
%
%Since we only have a limited number of prediction of the emulator for different values of $b$ (black points
%in Figure \ref{fignofitted}), we would like to extrapolate/interpolate those results to get
%more data and with that extra data, assess the value of $b$. As explained in Chapter 2, one very useful 
%way to obtain the extra data is through Gaussian processes. Using the language of the previous chapter
%what we want to do is, having the training points $\{(x_{i},f(x_{i})\}_{i=1}^{10}$ we want to predict 
%the value of different test points $x_{i}^{*}$. This prediction is shown as a red line in Figure
%\ref{fignofitted}.  The GP fit allows us to approxiamte as much value as we want, along with the uncertainty
%associated with the prediction. Having this data we can now proceed to use the Bayesian methodology.
%The idea goes as follows. if we denote the GP fit at at point $b$ as  $G(b)$, then we may assume
%an additive noise model for the output $y$ as
%\begin{equation}\label{eqnadditivenoise}
%y=G(b)+\vec{\epsilon}.
%\end{equation}
%$\vec{\epsilon}$ is a random vector distributed as $\vec{\epsilon}\sim\mathscr{N}(0,\sigma I)$. Where $sigma=bla$
%and $I$ is the $10\times 10$ identity matrix.
%In the Bayesian framework we are interest in finding the value of $b$ given the experimental measurements $m$.
%To that end we go back to the begining of this chapter and use equation (\ref{eqnpropto}). To use this equation
%we need to find the likelihood $\like(m|b)$. Under the assumption of the additive noise model in equation
%(\ref{eqnadditivenoise}) we get as in the smashed window example in chapter 2 that
%\begin{equation*}
%m|b\sim\mathscr{N}(G(b),\sigma I),
%\end{equation*}
%more precisely
%\begin{equation*}
%\like(m|b)=\frac{1}{(2\pi\sigma)^{n/2}}\exp\left(-\frac{\|G(b)-m\|_{2}^{2}}{2\sigma^{2}}\right).
%\end{equation*}
%
%
%
%Now we need to choose a prior for $b$. This is a delicate issue and a polemic one in the Statistics community.
%The prior should reflect all of our current knowledge about $b$. However your knowledge about $b$ might be 
%different than my knowledge about $b$, hence your prior for $b$ might look different than mine. For
%the moment  we won't worry about that. Let's assume that our prior for $b$ is given by
%\begin{equation*}
%b\sim U(0,2).
%\end{equation*}
%where $U(a,b)$ is the uniform distribution in $a,b$. Putting all of this into formula (\ref{eqnpropto}) we get
%\begin{equation*}
%\post(b|m)\propto\chi_{[0,2]}\exp\left(-\frac{\|G(b)-m\|_{2}^{2}}{2\sigma^{2}}\right),
%\end{equation*}
%where $\chi_{[a,b]}$ is the indicator function of the set $[a,b]$. This equation can be 
%interpreted as the update in knowledge from to prior to the posterior in the light of the
%experimental data obtained represented by the likelihood. This change from prior to 
%posterior is shown below.
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{./FigChap3/prior_posterior.jpg}
\caption{Plots of the prior distribution, posterior distribution and true value of the parameter $b$.}
\label{figlikeprior}
\end{figure} 

It is not always possible to visualize a probability density so it is necessary to sample from it
in order to obtain statistics about the parameters of interest.
A family of methods for this purpose
are known as Markov Chain Monte Carlo (MCMC). In this work we 
focus on a particular algorithm known as Metropolis-Hastings  (MH). We now proceed  to explain
how MH works in practice using the posterior for $b$ in equation (\ref{eqnposteriorforb}) as an example. 
\newline
\newline
Consider the posterior density $\post(b|\y)$. The idea is to construct a markov chain that wanders 
around the support of the posterior
in a way that the chain spends more time in regions with high probability.
One way to achive that is as follows: if we are at a point $q_{1}$ and we want to move to a point $q_{2}$ 
we will accept 
that move with probability one if $\post(q_{1}|\y)\leq\post(q_{2}|\y)$ and with probability 
$\frac{\post(q_{2}|\y)}{\post(q_{1}|\y)}$.  We choose
in what direction to move, randomly, using some probability distribution that is easy to sample from.
For simplicity, In this and the next Chapter we chose the uniform distribution to decide in what  direction to move.
The pseudocode  for the MH algorithm as described above is \cite{Somersalo}

\begin{algorithm}
\caption{Metropolis-Hastings Algorithm}
\begin{algorithmic}[1]\label{algMH}
\State pick a point $q_{1}$ in the support of the distribution
\For{j=2:N}
\State Draw $u\sim U([0,\alpha])$
\State $q_{j}\leftarrow q_{j-1}+u$
\State $\beta\leftarrow\min(1,\frac{\post(q_{j}|D)}{\post(q_{j-1}|\y)})$
\State Draw $w\sim U([0,1])$
\If{$w<\beta$}
\State $q_{j-1}=q_{j}\qquad$ (Accept the move)
\Else
\State $q_{j-1}=q_{j-1}\qquad$ (Reject the move)
\EndIf
\EndFor
%\\
%\textbf{for} j=2:N
%\item $\qquad$Draw $u\sim U([0,\alpha])$
%\item $$
%\item $\qquad$Compute $\post(q_{j}|D)$
%\item $\qquad$
%\item $\qquad$\\
%\\
%$\qquad\qquad\qquad$\textbf{if} $w<\beta$ 
%\item $\qquad\qquad q_{j-1}=q_{j}$\qquad(Accept move)\\
%\\
%$\qquad\qquad$\textbf{else}
%\item
%	$\qquad\qquad q_{j-1}=q_{j-1}$\\
%\textbf{end}\\
%\textbf{end}
\end{algorithmic}
\end{algorithm}

The rule of thumb for choosing the parameter $\alpha$ in the scheme above is that   the proportion of times we accept
a move 
is about $0.25$ \cite{casella2008monte}. It can be shown that the sequence $q_{1},q_{2},\ldots,q_{N}$
are realizations of a Markov chain that in the limit as $N\rightarrow\infty$ are distributed according to the distribution
$\post(b|\y)$. This convergence result works under mild conditions over the distribution that is being sampled from.
For more details about the theory behind MCMC methods we refer the reader to \cite{casella2008monte}. 
Since we do not have the computational power to let $N\rightarrow\infty$. We let the chain run for a large number of steps
until it converges. Then, we throw away the \textit{burn-in} portion of the chain and compute statistics using 
the remaining samples.  The burn-in portion of the chain are the samples obtained before the chain is close 
to converge. A common choice is to discard the first $\frac{N}{2}$ samples.
\newline


Using Algorithm 1, we sample from the posterior distribution $\post(b|\y)$ setting the values $\alpha=0.23$
and $N=10000$. The  burn-in  period is set to be  the first $5000$ samples. An histogram of the last $5000$
is shown below.

%Returning to the problem of sampling the posterior distribution for $b$. We are going to use the Metropolis Hastings algorithm
%using an step size of $\delta=0.23$, $10000$ samples and we chose the first $5000$ to be the burning period. The results 
%of applying the MH algorithm is shown below  
%


\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{./FigChap3/histogram_mcmc.jpg}
\caption{Histogram obtained for the posterior distribution (\ref{eqnpropto}) 
from $5000$ samples from MH algorithm with step size $\alpha=0.23$. The solid line
is the  graph for the posterior $\post(b|D)$.}
\end{figure}

With the samples obtained we readily obtain useful statistics for $b$. For example, we can estimate
the conditional mean using \cite{casella2008monte}

\begin{equation}\label{eqnbcmMC}
b_{cm}=\int_{(0,2]}b\post(b|D)db\approx\frac{1}{5000}\sum_{j=1}^{5000}b_{j}=0.9247042,
\end{equation}
where the summands $b_{j}$ are the samples obtained after the burn-in period of $5000$ samples. We can 
also estimate the variance of the samples as
\begin{equation*}
\int_{(0,2]}(b-b_{cm})^{2}\post(b|D)db\approx\frac{1}{5000}\sum_{j=1}^{5000}(b_{j}-b_{cm})^{2}=0.01427.
\end{equation*}
With these values we can compute a $95\%$ confidence interval for $b$. In this
case the interval is given by 
\begin{equation*}
[0.9247042-2\sqrt{0.01427},0.92470422+2\sqrt{0.01427}]=[0.68579,1.163618].
\end{equation*}


Let us digress about the idea behind Monte Carlo integration. Consider the generic problem of evaluating the $n$-dimensional
integral
\begin{equation}\label{eqnmontecarlo}
\int_{\mathbb{R}^{n}}h(x)\rho(x)dx,
\end{equation}  
where $\rho$ is the Lebesgue density of some probability measure $\p$. This means that calculating (\ref{eqnmontecarlo}) 
is equivalent to calculating the expected value of $h$, i.e.
\begin{equation*}
\mathbb{E}[h]=\int_{\mathbb{R}^{n}}h(x)\rho(x)dx.
\end{equation*}
If we have $X_{1},\ldots,X_{n}$ random variables independent with density $\rho$, then by the strong law of large numbers, the sequence of random
variables
\begin{equation*}
h_{n}=\frac{1}{n}\sum_{k=1}^{n} h(X_{k}),
\end{equation*}
converges to $\mathbb{E}[h]$\cite{dudley2002real}. Furthermore if $\mathbb{E}[h^{2}]<\infty$ we can assess the speed of
convergence and the quality of the approximation $h_{n}$ for $\mathbb{E}[h]$. By the central limit theorem
the sequence of random  variables $h_{n}$
\begin{equation*}
\frac{h_{n}-\mathbb{E}[h]}{\sqrt{\sigma_{n}}}\rightarrow \mathcal{N}(0,1),
\end{equation*}
where 
\begin{equation*}
\sigma_{n}=\frac{1}{n}\sum_{k=1}^{n}(h(X_{k})-h_{n})^{2}.
\end{equation*}
This means that the uncertainty in the approximation $h_{n}$ for $\mathbb{E}[h]$ goes to $0$ as $\mathcal{O}(\frac{1}{\sqrt{n}})$.
In practice, to estimate the quality of the result from the Monte Carlo integration we use the approximation
\begin{equation*}
\p\left(\frac{h_{n}-\mathbb{E}[h]}{\sqrt{\sigma_{n}}}\leq x\right)\approx\Phi(x),
\end{equation*}
where 
\begin{equation*}
\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}\exp(-\frac{x^{2}}{2})dx.
\end{equation*}
\newline

To conclude this Chapter we are going to turn our attention into the subjective part of Bayesian statistics.  We are 
going to talk about  the role the  prior probability has in the inference process. 

\textbf{You need to check this part. It looks rush you have to be more careful in the explanations.}


\section{The Importance of the Prior}
Once again  consider  problem of estimating
the value of the parameter $b$, whose real value is, as before, $0.925$. This time we assume the parameter
$b$ can be any real number (not just $0<b\leq 2$ as before) and the  prior distribution for $b$ is
\begin{equation*}
b\sim\mathscr{N}(b^{*},\sigma_{b}^{2}),
\end{equation*}
where $b^{*}$ and $\sigma_{b}$ are parameters to be set later.  With this new prior the formula
for the posterior is 
\begin{equation*}
\post(b|\textbf{y})\propto\underbrace{\exp\left(-\frac{\|\textbf{y}-\textbf{G}(b)\|_{2}^{2}}{2\sigma^{2}}\right)}_{\text{Likelihood}}\underbrace{\exp\left(-\frac{(b-b^{*})^{2}}{2\sigma_{b}^{2}}\right)}_{\text{Prior}}.
\end{equation*}
To illustrate the role that the prior has in the inference of the value
of the parameter given the data $\textbf{y}$, suppose that 
\begin{equation*}
b\sim\mathscr{N}(4,2.5).
\end{equation*}
This prior assumes that, with $95\%$ of confidence, the value of
$b$ is in the interval $[1.8,8.2]$. Clearly, there is a mismatch between
the true value of $b$ and the range of values that the prior distribution
assigns high probability. Let us evaluate how the posterior
distribution for $b$ evolves as we consider more and more experimental
data from the measurements of $\tilde{u}$. Figure \ref{figpostevolution} shows
how the posterior evolves when we calculate the likelihood with more 
and more data. The first frame shows the result when only the measurement
$\tilde{u}(\x_{1};b)$ is taken into account. The second frame
when the measurements $\tilde{u}(\x_{1};b),\tilde{u}(\x_{2};b)$ are taken
into account and so on. In each frame we proceed adding one more measurement 
at a time.

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{./FigChap3/posterior_evolution}
\caption{Evolution of the posterior distribution when more experimental data is taken into account}
\label{figpostevolution}
\end{figure}

The sequence of plots in Figure \ref{figpostevolution} shows that the experimental data creates a new mode
in the posterior distribution that is close to the true value of $b$. In the end of the sequence where we consider
all 10 experimental measurements, the mode that is close to the true value of $b$ is bigger than the mode originated
by the prior at the point $b=4$. The explanation for this behavior  is that the prior  has a high value near $b=4$, 
but it is close to zero for values around $b=0.925$.
Then, when the experimental data is used, the likelihood distribution has a higher  value for points  close to $b=0.925$
than points close to $b=4$. The more data, the higher the value of the likelihood around $b=0.925$ and closer to zero
away from it. However since
the prior distribution gives negligible probability to values close to the true value of $b$, when all data are used the 
product $\prior(\y|b)\p(b)$ will be noneglibible only in regions close to $b=4$ or $b=0.925$.

The above example is a warning example. If we know how to choose the prior distribution in a way that is meaningful to the
problem, reliable inference could be done even with small amount of data. On the contrary if the prior distribution
is not realistic, inference could not be done or  may not be reliable even with a large amount of data.  
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Chapter 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\chapter{Industrial Case Problem}



As mentioned in the introduction, our interested is to study
the dispersion of zinc from a lead-zinc smelter in Trail, British Columbia, Canada
operated by Teck Industries Ltd.  The smelter has four sources of pollutant and our goal
is to estimate how much  each source is contributing to the total amount of zinc
that is being released by the smelter.
To estimate this we count on experimental
measures of the zinc deposition in nine different locations and wind velocity data 
of the surrounding area. An aerial photograph of the region  of interest with 
the location of the sources and the measurement devices is shown 
in Figure \ref{figAereal}. 

 

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{FigChap4/AerealView}
\label{figAereal}
\caption{Aereal photograph of the lead-zinc smelter in Trail, British Columbia, Canada. The points
$Q_{1}$ to $Q_{4}$ represent the sources of zinc. The green triangles $R_{1}$ to $R_{9}$ represent
the location of the measurement devices.}
\end{figure}

The first step in order to estimate the contribution of each source in the total
input of zinc into the atmosphere is to formulate a mathematical model that approximates
the physics behind the pollutant dispersion.
%To estimate the contribution of the sources we are going to proceed in the same
%manner as in the previous chapter. First we formulate the mathematical model
%that describes the physics of interest. With the model we proceed to find
%the likelihood. Next we use any given information about the source to choose
%a prior




\section{A Mathematical Model for Pollutant Dispersion}
Our starting point  is the conservation of mass. In particular conservation of mass for
particulated zinc in the atmosphere. Consider a region of space  $V$ with $m$ units of   mass
of zinc within it. 
Assume
that in the interior of $V$ there is  a source of  zinc. Further assume that zinc is flowing throughout 
the boundary $\partial V$ of $V$  due to  wind (see Figure bla).
If $\vv(\x,t)$ represents the wind velocity at a point $\x$ at time $t$, it can be shown that net amount
per unit time of zinc that is flowing through the boundary is given by the expression
\cite{seinfeld1998atmospheric}
\begin{equation*}
\oint_{\partial V}c(\x,t)\vv(\x,t)\cdot\textbf{n}dA,
\end{equation*}
where  $c(\x,t)$ is the concentration of zinc at a point $\x$
at time $t$.
The units of $c$ are given in units of mass per units of volume. On the other hand
the rate of change total mass $m$ at a time $t$ inside $V$  can be calculated as
\begin{equation*}
\frac{dm(t)}{dt}=\frac{d}{dt}\int_{V}c(\x,t)dV.
\end{equation*}
Finally if the amount of zinc that comes from the source at a time $t$ is given by
\begin{equation*}
\int_{V}s(\x,t)dV,
\end{equation*}
where $s(\x,t)$ is the source density. Its units are mass per unit volume per unit time.
Conservation of mass states that the total mass inside $V$ should be conserved. Therefore
for all times the rate of change of the mass inside $m$ should equal all source of variation of it.
Mathematically we can write
\begin{equation*}
\frac{d}{dt}\int_{V}c(\x,t)dV=-\oint_{\partial V}c(\x,t)\textbf{v}\cdot\textbf{n}dA+\int_{V}s(\x,t)dV.
\end{equation*}
Since we picked the orientation of $\partial V$ with the normal pointing outwards, it is
necessary to put a minus in front of the surface integral for consistency. Assuming
the concentration and the velocity field are continuous functions of time and space, an 
straight forward application of the divergence theorem and Leibniz rule for integral gives
\begin{equation}\label{eqnDeterministic}
\frac{\partial c(\x,t)}{\partial t}+\nabla\cdot(c\textbf{v})=s(\x,t).
\end{equation}
If we apply this equation to estimate the concentration of zinc using real wind data, we 
will find that the prediction is not completely accurate. The reason is that at small scales, there
are random fluctuations in the wind velocity. To model this we follow \cite{seinfeld1998atmospheric}
and write the wind velocity as
\begin{equation}\label{eqnNewV}
\vv=\bar{\vv}+\vv',
\end{equation}
where $\bar{\vv}$ is the measured wind velocity and $\vv'$ is a random variable with zero mean.
If we replace $\vv$ in equation (\ref{eqnDeterministic}) with the expression for velocity
in equation (\ref{eqnNewV}) we get
\begin{equation}\label{eqnNewRandom}
\frac{\partial c(\x,t)}{\partial t}+\nabla\cdot(c(\bar{\textbf{v}}+\vv'))=s(\x,t).
\end{equation}
The presence of the random variable $\vv'$ transforms the solution $c$ into a random 
variable as well. In this case we describe $c$ as the contribution of two terms
\begin{equation*}
c=\E(c)+c',
\end{equation*}
where $c'$ satisfies $\E(c')=0$. The intuition behind this definition is that if we experimentally
measure the concentration repeating the same experiment a high number of times. We expect the 
concentration to have an underlying average behavior $\E(c)$ plus some  noise represented by $c'$.
Plugging in this new representation of $c$ into equation (\ref{eqnNewRandom}) we obtain
\begin{equation}\label{eqnInconsistent}
\frac{\partial\E(c)}{\partial t}+\dv(\bar{\vv}\E(c))+\dv(\E(c'\vv'))=s(\x,t).
\end{equation}
The problem with this new equation is  the extra variable $\E(c'\vv')$.
In this case we have two unknowns and one equation. 
One way to overcome this issue is given by the so-called mixing-length theory. The
theory uses the constitutive equation
\begin{equation*}
\E(c'\vv')=\textbf{D}\nabla(\E(c)).
\end{equation*}
The term $\textbf{D}$ is  a rank two tensor called the eddy diffusivity tensor. This tensor is assumed 
to be symmetric, hence is always diagonalizable. We may assume that we are working
in the principal axis of $\textbf{D}$. Note that  In general we do not have enough information to believe the tensor
to be non-diagonal \cite{seinfeld1998atmospheric}, hence 
\begin{equation*}
\textbf{D}=\begin{bmatrix}
D_{xx}& 0 & 0\\
0 & D_{yy} & 0\\
0 & 0 & D_{zz}
\end{bmatrix}.
\end{equation*}
Under the mixing-length theory, equation (\ref{eqnInconsistent}) reads as
\begin{equation*}
\frac{\partial\E(c)}{\partial t}+\dv(\bar{\vv}\E(c)+\textbf{D}\nabla\E(c))=s(\x,t).
\end{equation*}
The variable $\E(c)$ is a deterministic function of space and time. So to make
notation lighter  we set $C(\x,t):=\E(c)$. Note that $C$ has the same units
as $c$. We interpret $C(\x,t)$ as the expected concentration we would measure
 at the point $\x$ at time $t$ if we were to repeat a pollutant dispersion
experiment a large number of times under identical initial and boundary conditions.
The final form of the mathematical model for pollutant dispersion is

\begin{equation}\label{eqnDifussivityFinalForm}
\frac{\partial C(\x,t)}{\partial t}+\dv(\bar{\vv}C(\x,t)+\textbf{D}\nabla C(\x,t))=s(\x,t).
\end{equation}
Due to the presence of the diffusivity tensor, it is necessary to make assumptions about
the behavior of the diagonal elements of $\textbf{D}$. Also the measurements of the wind velocity
are given only at one point in space, hence is necessary to make further assumption in 
the wind speed distribution as well. 



\subsection{Assumptions on the Wind Velocity and Source Density}
In practice, the way we measure the wind velocity is by using anemometers that are capable to 
measure a two dimensional projection of the   velocity vector field.
Therefore
it is necessary to make assumptions on the three dimensional and global behavior of this vector field.
Following \cite{hosseini2016airborne}, we assume a velocity vector field of the form 
\begin{equation*}
\vv=(v_{x}(z,t),v_{y}(z,t),v_{set}),
\end{equation*}
where $v_{set}$ is a constant given by  the settling velocity of the zinc particles. By Stoke's law,
this velocity is given by
\begin{equation*}
v_{set}=\frac{\rho g d^{2}}{18\mu},
\end{equation*}
where $\rho$ is the particle density, $g$ the acceleration of gravity,  $d$ its diameter, and
$\mu$ is the air viscosity. For the $x,y$ components of $\vv$ a power law relation of the form
\begin{equation}\label{eqnPowerLaw}
\|(v_{x}(z,t),v_{y}(z,t))\|_{2}=v_{r}(t)\left(\frac{z}{z_{r}}\right)^{p},
\end{equation}
where $v_{r}(t)$  is the wind speed at a reference height $z_{r}$. The exponent $p$ depends on 
factors such as the surface roughness and atmosphere stability. For more details in the power
law model for the wind velocity the reader is referred to \cite{seinfeld1998atmospheric}.

For the source density we assume point-wise sources. If there are $n$ sources inside $\Omega$
located at the point $\x_{1},x_{2},\ldots,\x_{n}$,
then we assume a source density of the form
\begin{equation}\label{eqnSourceDensity}
s(\x,t)=\sum_{j=1}^{n}q_{j}(t)\delta(\x-\x_{j}).
\end{equation}
Here $q_{j}$ is referred as the  strength of the $j$-th source and has units of mass per unit time. 
The function $\delta(\cdot)$ is the Dirac delta function.

\subsection{Assumptions on the Diffusivity Tensor}
Following \cite{monin1954basic},  the vertical diffusivity coefficient $D_{zz}$ is approximated by
\begin{equation}\label{eqnEddyVertical}
D_{zz}=\frac{\kappa v_{*} z}{\phi(z/L)},
\end{equation}

Where $\kappa$ is the \textit{Von-Karman} constant whose value in practice is set as $0.4$. The denominator
is defined as the piece-wise continuous function
\begin{equation*}
\phi\left(\frac{z}{L}\right)=\left\{
			\begin{array}{ll}				
				1+4.7\frac{z}{L} &\mbox{for }\frac{z}{L}>0 \\
				1 &\mbox{for }\frac{z}{L}=0\\
				(1-15\frac{z}{L})^{-\frac{1}{2}}&\mbox{for }\frac{z}{L}<0
			\end{array}.
		\right.
\end{equation*}
Here $L$ is referred as the \textit{Monin-Obukhov length}. Finally the parameter $v_{*}$ is known as 
the \textit{friction velocity}. This parameter is a  function of a third variable known as 
the \textit{roughness length} $z_{0}$. 

For the elements $D_{xx}$ and $D_{yy}$, we assume $D_{xx}=D_{yy}$ and independence of height 
\cite{monin1954basic}. A common used equation
to approximate this variables is given by
\begin{equation*}
D_{xx}=D_{yy}\approx \frac{v_{*}z_{i}^{\frac{3}{4}}(-\kappa L)^{-\frac{1}{3}}}{10}.
\end{equation*}
The variable $z_{i}$ is known as the \textit{mixing layer height}.


Assuming an specific form of the functional form of the wind velocity and the  
diffusivity tensor, introduces new parameters whose value needs to be decided. In our model
there are five parameters we need to assign a value before we can use equation (\ref{eqnDifussivityFinalForm}).
These parameters are
\begin{itemize}
\item $p$: the fitting parameter for the wind velocity power law (equation (\ref{eqnPowerLaw}))
\item $z_{0}$: roughness length
\item $z_{i}$: mixing layer height.
\item $L$: Monin-Obukhov length.
\item $z_{cut}$ cutting height (equation (bla)).
\end{itemize}
In practice we set a value for these parameters from a given interval of numbers
that empirically has shown to work \cite{seinfeld1998atmospheric,hosseini2016airborne}.
The caveat with this approach is that there is no good reason to choose one value
over a different one. In this work we are going to use the Bayesian framework
to decide the values of this parameters and the sources as well.

Let us summarize what we have done so far. Our model is given by the solution
of equation (\ref{eqnDifussivityFinalForm}). The solution depends on the
parameters $p$,$z_{0}$,$z_{i}$,$L$,$z_{cut}$ and four sources $Q_{1},
Q_{2},Q_{3},Q_{4}$ (see Figure \ref{figAereal}). Symbolically we can 
write the solution $C$ in equation (\ref{eqnDifussivityFinalForm}) as
\begin{equation*}
C(\x,t;p,z_{0},z_{i},L,z_{cut},Q_{1},Q_{2},Q_{3},Q_{4}).
\end{equation*}
We have nine mesurements of the total deposition of zinc at the points $\{R_{1},\ldots, R_{9}\}$
of the total deposition per year. at the nine locations 
\begin{equation}
\y=\{M(R_{1}),\ldots,M(R_{9})\}.
\end{equation}
The relation between these two sets is given by
\begin{equation}\label{eqnSourceToMeasurements}
M(R_{j})=C(R_{j},t;allparameters)\Delta A.
\end{equation}
where $Delta A$ is the sectional area of the jars. It is well known that for equation (\ref{eqnDifussivityFinalForm}) the behavior of $C$ 
with respect to the source is linear, we can split relation (\ref{eqnSourceToMeasurements}) as
\begin{equation*}
\y= B(p,z_{0},z_{i},L,z_{cut})\textbf{q}\Delta A,
\end{equation*}
where $\textbf{q}:=[Q_{1},Q_{2},Q_{3},Q_{4}]^{T}$. The term $B(p,z_{0},z_{i},L,z_{cut})$ is a $4\times 9$ matrix. We have made explicit
the dependence of the entries of this matrix with the parameters $p,z_{0},z_{i},L,z_{cut}$. Having to calculate 36 elements 
that depend on $5$ parameters is expensive. Therefore we may ask if there is a way to reduce the size of the parameter space.
As explained in Chapter 2 we can perform a sensitivity analysis to assess the importance of each parameter

\section{Sensitivity Analysis}
We do a sensitivity analysis on the 5 space parameters as explained in Chapter 2. Using the sobol index technique we
got the following result
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./FigChap4/sensitivityPlot}
\caption{The sensitivity plot}
\end{figure}
As we can see we only need to worry about the parameters $p,z_{0},L$.
Now we can write the matrix $B$ as $B(p,z_{0},L)$. Evualating $36$ elements
is expensive hence we need to use GPs

\section{Design of Experiments and Emulator for $B$}
We need to create 36 GPs to approximate $B$, first we need to decide where to evaluate the model in order
to find the points where to run the model (\ref{eqnDifussivityFinalForm}). We do a maximin design
as explained in Chapter 2. To do the optimization we used particle swarm. With $N=64$ the design looks as follows.
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{./FigChap4/experimentalDesign64}
\caption{the experimental design plot}
\end{figure}
We now run the finite element code on the points chosen by the experimental design. With this
values we build the emulator for $B$. We denote this emulator by $\widehat{B}$. As
in Chapter 3 we now assume a model of the form
\begin{equation}\label{eqnEpsilonApproxChp4}
\y=\widehat{B}\textbf{q}\Delta A+\epsilon,
\end{equation}
with $\epsilon$ multivariate Gaussian. No we have all the ingredients to use 
the Bayesian framework to estiamte the parameters and the sources. 
\begin{equation*}
\post(p,z_{0},L,\q|\y)=\frac{\like(\y|p,z_{0},L,\q)\prior(p,z_{0},L,\q)}{Z(\y)}.
\end{equation*}
As in Chapter 3, from equation (\ref{eqnEpsilonApproxChp4}) we conclude that
\begin{equation*}
\y|\pars,\q\sim\mathcal{N}(0,\lambda I).
\end{equation*}
Hence the only thing that is left to calculate is the prior
\section{Choosing a Prior}
First it is resonable to assume
\begin{equation*} 
\prior(\pars,\q)=\prior(\pars)\prior(\q).
\end{equation*}
So we need to take care about $\pars$ and $\q$ separately. For the values of $\pars$ we follow \cite{hosseini2016airborne}
and assume that the parameters belong to the following ranges
\begin{center}
\textbf{Here you put the table with the range of the acceptable values}
\end{center}
Since we don't have any other information than that we assume an uniform distribution.
For $\q$ we have more information according to \cite{hosseini2016airborne}, engineerings have estimate
the following values for the components of $\q$
\begin{center}
\textbf{Here you put a table with the estimates from the engineers}
\end{center}
Using this data we may pose that $\q$ is disributed as $G(\alpha,\beta)$,\textbf{You have to explain
how to determine the values of the parameters of the distribution}
Having these two quantities, our posterior now looks like
\begin{equation*}
\post(\pars,\q|\y)\propto\mathcal{N}(0,\lambda I)U(a,b)G(\alpha,\beta)
\end{equation*}

Having an explicit expression of the posterior allows us to sample from it to 
obtain useful statistics.

\section{Inferring the Parameters and the sources}
Here you put the results from using MH on the posterior
and then calculate all the useful statistics.





\bibliography{Tesis}
\bibliographystyle{plain}
\end{document}
